{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9fdae31a34f24d9ca9d0dd28bdeb9501":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ca7b6ebb45a4778a8ec2c5410428136","IPY_MODEL_d3b5cddfdcc24d6cb06c47d6f7b1021c","IPY_MODEL_088fb23d67d546cbaa9e7e2ae0dc29d1"],"layout":"IPY_MODEL_5e2a0f195bf04b50b771b2c95df52705"}},"3ca7b6ebb45a4778a8ec2c5410428136":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e972706b5e7648f5b763643770257d18","placeholder":"​","style":"IPY_MODEL_002e9e0f195d4b0ca6ca82ebc0a36fca","value":"tokenizer_config.json: 100%"}},"d3b5cddfdcc24d6cb06c47d6f7b1021c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_671c8caa5d464cc19bd0c77d63b0738a","max":7305,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e71684bb7b5a45eda8ac14b971b22801","value":7305}},"088fb23d67d546cbaa9e7e2ae0dc29d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d95247755ff24b61a2409935ed3f3803","placeholder":"​","style":"IPY_MODEL_76b01f3ce73d4a919f0b79f796437408","value":" 7.30k/7.30k [00:00&lt;00:00, 413kB/s]"}},"5e2a0f195bf04b50b771b2c95df52705":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e972706b5e7648f5b763643770257d18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"002e9e0f195d4b0ca6ca82ebc0a36fca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"671c8caa5d464cc19bd0c77d63b0738a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e71684bb7b5a45eda8ac14b971b22801":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d95247755ff24b61a2409935ed3f3803":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76b01f3ce73d4a919f0b79f796437408":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f681c4d257a486bb5f19a094b77a6a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a370f950431a4a7c998c5423478fc2eb","IPY_MODEL_b98d890356b14d148d8c2fddd6ee5d56","IPY_MODEL_e9265614883546cc8af327c857d95619"],"layout":"IPY_MODEL_4df58152399d4c0fa41ad4679a9852c3"}},"a370f950431a4a7c998c5423478fc2eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56ef40ae11bb4820bc58ddb6af2e2cb8","placeholder":"​","style":"IPY_MODEL_7457ba7a06c44272b56782465dbed435","value":"vocab.json: 100%"}},"b98d890356b14d148d8c2fddd6ee5d56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b623d92b5e944fa99e417267b238f29","max":2776833,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9200fc3de7e64c64a6c9766903030f58","value":2776833}},"e9265614883546cc8af327c857d95619":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f35d5d6adedb497eab4eb222ec72a9cc","placeholder":"​","style":"IPY_MODEL_8adeb562701749c0b47d8ce95a23c528","value":" 2.78M/2.78M [00:00&lt;00:00, 11.3MB/s]"}},"4df58152399d4c0fa41ad4679a9852c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56ef40ae11bb4820bc58ddb6af2e2cb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7457ba7a06c44272b56782465dbed435":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b623d92b5e944fa99e417267b238f29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9200fc3de7e64c64a6c9766903030f58":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f35d5d6adedb497eab4eb222ec72a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8adeb562701749c0b47d8ce95a23c528":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7c2438ab0ee481da8522476244cf4d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_683123b79cc64499a6945e75a99dab69","IPY_MODEL_13983bb7cf2c4fd9bed4850efb6e90c1","IPY_MODEL_3cf33f2cd60041509bb863847f82d043"],"layout":"IPY_MODEL_c557c68d842743efa6443f6f84901dfa"}},"683123b79cc64499a6945e75a99dab69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f367547ce32b476c82584c83058d0aba","placeholder":"​","style":"IPY_MODEL_809fa7b7e0e74eba8b79f3f3004c3315","value":"merges.txt: 100%"}},"13983bb7cf2c4fd9bed4850efb6e90c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_00e24ad773a5438493e77ccdbb0e1e4c","max":1671839,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a2352df87354a5492481237bc371c72","value":1671839}},"3cf33f2cd60041509bb863847f82d043":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46f2999985d24862af9990714fa861fe","placeholder":"​","style":"IPY_MODEL_13d7d89b90ee4259bae898930e1c7ae7","value":" 1.67M/1.67M [00:00&lt;00:00, 5.72MB/s]"}},"c557c68d842743efa6443f6f84901dfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f367547ce32b476c82584c83058d0aba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"809fa7b7e0e74eba8b79f3f3004c3315":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00e24ad773a5438493e77ccdbb0e1e4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a2352df87354a5492481237bc371c72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"46f2999985d24862af9990714fa861fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13d7d89b90ee4259bae898930e1c7ae7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ce7a5f815444fa9a860009fcee2c386":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f6f5c834136435c9a59fc88efeb34a0","IPY_MODEL_ffbe9986b12c40b69443041ae3a9f93a","IPY_MODEL_0e0046dc6cb94fae91fb8e666d763865"],"layout":"IPY_MODEL_b25e3749426446bca0ac4640a0a31f41"}},"9f6f5c834136435c9a59fc88efeb34a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6794173ed3a845b8936d82966ad8a2e3","placeholder":"​","style":"IPY_MODEL_0e2bd0058e3b4966ba2bba872eb64af6","value":"tokenizer.json: 100%"}},"ffbe9986b12c40b69443041ae3a9f93a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3261d4157d544d28a8004b63a58aec4d","max":7031645,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0edaf671649246fca56b51a04f95a65d","value":7031645}},"0e0046dc6cb94fae91fb8e666d763865":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d300d7e7d74d42f78287b6c0e2a7243f","placeholder":"​","style":"IPY_MODEL_fa5e9195d23c4153a6787e90024709b2","value":" 7.03M/7.03M [00:00&lt;00:00, 16.1MB/s]"}},"b25e3749426446bca0ac4640a0a31f41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6794173ed3a845b8936d82966ad8a2e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e2bd0058e3b4966ba2bba872eb64af6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3261d4157d544d28a8004b63a58aec4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0edaf671649246fca56b51a04f95a65d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d300d7e7d74d42f78287b6c0e2a7243f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa5e9195d23c4153a6787e90024709b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e8baceb38e54bfe81aa528aace6889d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc989edfe92a4534bcd8d2df8c3b0d95","IPY_MODEL_0b26e88f61404aa18dd29c7d9fa3fd0a","IPY_MODEL_0eb3e2f347564f10a7ed62ba0dc05c72"],"layout":"IPY_MODEL_80b5e6e41320404cb185e5c1ec312fcd"}},"bc989edfe92a4534bcd8d2df8c3b0d95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd3bd23325784e16b8b65feef0c17aa8","placeholder":"​","style":"IPY_MODEL_4deb162996da4072af3a8b745655526b","value":"config.json: 100%"}},"0b26e88f61404aa18dd29c7d9fa3fd0a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bee9206491448a8a5d74baf2c7a97ca","max":659,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8ad88f4056646399c40a5dd08f58121","value":659}},"0eb3e2f347564f10a7ed62ba0dc05c72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e18e8c27da34bfd958966ff0401906f","placeholder":"​","style":"IPY_MODEL_8391b8dc32844d5ab2d19f158e1bb3ef","value":" 659/659 [00:00&lt;00:00, 50.5kB/s]"}},"80b5e6e41320404cb185e5c1ec312fcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd3bd23325784e16b8b65feef0c17aa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4deb162996da4072af3a8b745655526b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bee9206491448a8a5d74baf2c7a97ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8ad88f4056646399c40a5dd08f58121":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e18e8c27da34bfd958966ff0401906f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8391b8dc32844d5ab2d19f158e1bb3ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b7baa41109047abbccb37f07bb7eed3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbeb860bbe664441ba9ea6ab21035909","IPY_MODEL_de196235199c45b9bc7ecbacd4de8b3f","IPY_MODEL_869017e4755b4978b7ce6f167f3f4fa1"],"layout":"IPY_MODEL_a972629a5c68453ea155885b8683654c"}},"bbeb860bbe664441ba9ea6ab21035909":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d326f6a8687c449982dda99e290a8a45","placeholder":"​","style":"IPY_MODEL_a1143854813d46fca31273cc8735e7ff","value":"model.safetensors: 100%"}},"de196235199c45b9bc7ecbacd4de8b3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b303efd0833042a8bf738b2757572952","max":988097824,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9bcbbec6a42d49e58e5989b471823d1b","value":988097824}},"869017e4755b4978b7ce6f167f3f4fa1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9f57499396e49cb955cdbb749be2fe9","placeholder":"​","style":"IPY_MODEL_a8640c71ca454e8c916985163a38ae86","value":" 988M/988M [00:09&lt;00:00, 142MB/s]"}},"a972629a5c68453ea155885b8683654c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d326f6a8687c449982dda99e290a8a45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1143854813d46fca31273cc8735e7ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b303efd0833042a8bf738b2757572952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bcbbec6a42d49e58e5989b471823d1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9f57499396e49cb955cdbb749be2fe9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8640c71ca454e8c916985163a38ae86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2010773772c64ed9a39810d0d99688f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9039f1570d7e4f87add295f1ddbd0f00","IPY_MODEL_b48c8ab2e15146009d37d34ee74abc74","IPY_MODEL_8c0af652b78840fa8e52ff0bba87ed66"],"layout":"IPY_MODEL_a72e75ecba3d48b6a12906dea1696003"}},"9039f1570d7e4f87add295f1ddbd0f00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90856bc01abe4b528d252805f6ad7b14","placeholder":"​","style":"IPY_MODEL_352892b76c074b4d954404825e9fc61d","value":"generation_config.json: 100%"}},"b48c8ab2e15146009d37d34ee74abc74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9bf715b1bc64e529d0b4a9629cf7b1b","max":242,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e074070b1d24f1d94a31d74e9eab535","value":242}},"8c0af652b78840fa8e52ff0bba87ed66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07ff01eaa3a4469da089993c5d352fc0","placeholder":"​","style":"IPY_MODEL_6b85ad7dd96d413785925e0a9b57dbe5","value":" 242/242 [00:00&lt;00:00, 6.01kB/s]"}},"a72e75ecba3d48b6a12906dea1696003":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90856bc01abe4b528d252805f6ad7b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"352892b76c074b4d954404825e9fc61d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9bf715b1bc64e529d0b4a9629cf7b1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e074070b1d24f1d94a31d74e9eab535":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07ff01eaa3a4469da089993c5d352fc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b85ad7dd96d413785925e0a9b57dbe5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa722f3c0ec0418f9d61e9619ab92d52":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7221e239c655427dab04669871eb938a","IPY_MODEL_06f678cd16914a75a0e8ad904c7240af","IPY_MODEL_0c3e1bd0cded45f99e34ee7f6810ac19"],"layout":"IPY_MODEL_eeb700948afc47a0bc63a349e85ababe"}},"7221e239c655427dab04669871eb938a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a476ffec28b4c56984c792c597e4c8a","placeholder":"​","style":"IPY_MODEL_146b9a1f89034bc7b9ff1013811b42e4","value":"Packing train dataset: 100%"}},"06f678cd16914a75a0e8ad904c7240af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69e0adfd75f5498f874fdd055c41af7e","max":70465,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2bf0454c45246f4a41c33c417aa22f1","value":70465}},"0c3e1bd0cded45f99e34ee7f6810ac19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf50d895e3e44609a7b12f01c5054161","placeholder":"​","style":"IPY_MODEL_c162a9fb11d342628a3412a650aed318","value":" 70465/70465 [00:07&lt;00:00, 5117.05 examples/s]"}},"eeb700948afc47a0bc63a349e85ababe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a476ffec28b4c56984c792c597e4c8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"146b9a1f89034bc7b9ff1013811b42e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69e0adfd75f5498f874fdd055c41af7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2bf0454c45246f4a41c33c417aa22f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf50d895e3e44609a7b12f01c5054161":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c162a9fb11d342628a3412a650aed318":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdf4f6c8ea504871aa0f2f88066800b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87320e00eed84793bd6c450923483747","IPY_MODEL_cebc701042834e58806924526425f76d","IPY_MODEL_4b64521b164f4ba9b3433b6a1ddbc658"],"layout":"IPY_MODEL_0d29c08d26164386a7b76c6f0267ff85"}},"87320e00eed84793bd6c450923483747":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fefcf2e136d3459a891ad9040d1c6b1e","placeholder":"​","style":"IPY_MODEL_48e89d1f6b8a42ae860eaff6d78e0fe4","value":"Packing eval dataset: 100%"}},"cebc701042834e58806924526425f76d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a842ba83af0044119059283df2beb85b","max":3709,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dfcd8787a1cc4538bbc163e3346c298f","value":3709}},"4b64521b164f4ba9b3433b6a1ddbc658":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66a28d6011cd4859a22e9359d293efb9","placeholder":"​","style":"IPY_MODEL_160ab91e81af43f7b59f4ab764ce5e91","value":" 3709/3709 [00:00&lt;00:00, 42157.41 examples/s]"}},"0d29c08d26164386a7b76c6f0267ff85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fefcf2e136d3459a891ad9040d1c6b1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48e89d1f6b8a42ae860eaff6d78e0fe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a842ba83af0044119059283df2beb85b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfcd8787a1cc4538bbc163e3346c298f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66a28d6011cd4859a22e9359d293efb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"160ab91e81af43f7b59f4ab764ce5e91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup env","metadata":{"id":"LOiBMoL-2U5v"}},{"cell_type":"code","source":"# Install required packages\n!pip install -q torch transformers datasets accelerate bitsandbytes trl peft lighteval huggingface_hub einops\n!pip install -q -U lighteval tiktoken lighteval[\"extended_tasks\"] lighteval[math]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwjGu1dy4k14","outputId":"9e606de9-039f-4f11-e625-82e10e8d2868","trusted":true,"execution":{"iopub.status.busy":"2025-03-31T02:27:16.206232Z","iopub.execute_input":"2025-03-31T02:27:16.206452Z","iopub.status.idle":"2025-03-31T02:27:39.712534Z","shell.execute_reply.started":"2025-03-31T02:27:16.206430Z","shell.execute_reply":"2025-03-31T02:27:39.711460Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nomegaconf 2.3.0 requires antlr4-python3-runtime==4.9.*, but you have antlr4-python3-runtime 4.13.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Restart runtime\nimport os\nos.kill(os.getpid(), 9)","metadata":{"id":"WDCg2SB9-HG7","trusted":true,"execution":{"execution_failed":"2025-03-31T02:27:40.441Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import required libraries\nimport os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    pipeline\n)\nfrom peft import LoraConfig, get_peft_model\nfrom trl import SFTTrainer, SFTConfig","metadata":{"id":"LxkahJpq1iRv","trusted":true,"execution":{"iopub.status.busy":"2025-03-31T02:27:45.995779Z","iopub.execute_input":"2025-03-31T02:27:45.996213Z","iopub.status.idle":"2025-03-31T02:28:21.646621Z","shell.execute_reply.started":"2025-03-31T02:27:45.996178Z","shell.execute_reply":"2025-03-31T02:28:21.645991Z"},"scrolled":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Login to HuggingFace (https://huggingface.co/settings/tokens)\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nhf_key = user_secrets.get_secret(\"hf_key\")\nlogin(token=hf_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T02:28:21.647580Z","iopub.execute_input":"2025-03-31T02:28:21.647852Z","iopub.status.idle":"2025-03-31T02:28:21.906539Z","shell.execute_reply.started":"2025-03-31T02:28:21.647831Z","shell.execute_reply":"2025-03-31T02:28:21.905642Z"},"scrolled":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Evaluate instruct model","metadata":{"id":"fJYEmWJq2YF4"}},{"cell_type":"code","source":"# Load instruct model\n\nfrom accelerate import infer_auto_device_map\n\n# Model ID for the instruct version\ninstruct_model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n# Load tokenizer\ninstruct_tokenizer = AutoTokenizer.from_pretrained(instruct_model_id)\n\n# Configure model loading with 4-bit quantization for memory efficiency\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load the model\ninstruct_model = AutoModelForCausalLM.from_pretrained(\n    instruct_model_id,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386,"referenced_widgets":["9fdae31a34f24d9ca9d0dd28bdeb9501","3ca7b6ebb45a4778a8ec2c5410428136","d3b5cddfdcc24d6cb06c47d6f7b1021c","088fb23d67d546cbaa9e7e2ae0dc29d1","5e2a0f195bf04b50b771b2c95df52705","e972706b5e7648f5b763643770257d18","002e9e0f195d4b0ca6ca82ebc0a36fca","671c8caa5d464cc19bd0c77d63b0738a","e71684bb7b5a45eda8ac14b971b22801","d95247755ff24b61a2409935ed3f3803","76b01f3ce73d4a919f0b79f796437408","0f681c4d257a486bb5f19a094b77a6a9","a370f950431a4a7c998c5423478fc2eb","b98d890356b14d148d8c2fddd6ee5d56","e9265614883546cc8af327c857d95619","4df58152399d4c0fa41ad4679a9852c3","56ef40ae11bb4820bc58ddb6af2e2cb8","7457ba7a06c44272b56782465dbed435","7b623d92b5e944fa99e417267b238f29","9200fc3de7e64c64a6c9766903030f58","f35d5d6adedb497eab4eb222ec72a9cc","8adeb562701749c0b47d8ce95a23c528","e7c2438ab0ee481da8522476244cf4d9","683123b79cc64499a6945e75a99dab69","13983bb7cf2c4fd9bed4850efb6e90c1","3cf33f2cd60041509bb863847f82d043","c557c68d842743efa6443f6f84901dfa","f367547ce32b476c82584c83058d0aba","809fa7b7e0e74eba8b79f3f3004c3315","00e24ad773a5438493e77ccdbb0e1e4c","5a2352df87354a5492481237bc371c72","46f2999985d24862af9990714fa861fe","13d7d89b90ee4259bae898930e1c7ae7","8ce7a5f815444fa9a860009fcee2c386","9f6f5c834136435c9a59fc88efeb34a0","ffbe9986b12c40b69443041ae3a9f93a","0e0046dc6cb94fae91fb8e666d763865","b25e3749426446bca0ac4640a0a31f41","6794173ed3a845b8936d82966ad8a2e3","0e2bd0058e3b4966ba2bba872eb64af6","3261d4157d544d28a8004b63a58aec4d","0edaf671649246fca56b51a04f95a65d","d300d7e7d74d42f78287b6c0e2a7243f","fa5e9195d23c4153a6787e90024709b2","4e8baceb38e54bfe81aa528aace6889d","bc989edfe92a4534bcd8d2df8c3b0d95","0b26e88f61404aa18dd29c7d9fa3fd0a","0eb3e2f347564f10a7ed62ba0dc05c72","80b5e6e41320404cb185e5c1ec312fcd","fd3bd23325784e16b8b65feef0c17aa8","4deb162996da4072af3a8b745655526b","6bee9206491448a8a5d74baf2c7a97ca","a8ad88f4056646399c40a5dd08f58121","8e18e8c27da34bfd958966ff0401906f","8391b8dc32844d5ab2d19f158e1bb3ef","9b7baa41109047abbccb37f07bb7eed3","bbeb860bbe664441ba9ea6ab21035909","de196235199c45b9bc7ecbacd4de8b3f","869017e4755b4978b7ce6f167f3f4fa1","a972629a5c68453ea155885b8683654c","d326f6a8687c449982dda99e290a8a45","a1143854813d46fca31273cc8735e7ff","b303efd0833042a8bf738b2757572952","9bcbbec6a42d49e58e5989b471823d1b","d9f57499396e49cb955cdbb749be2fe9","a8640c71ca454e8c916985163a38ae86","2010773772c64ed9a39810d0d99688f4","9039f1570d7e4f87add295f1ddbd0f00","b48c8ab2e15146009d37d34ee74abc74","8c0af652b78840fa8e52ff0bba87ed66","a72e75ecba3d48b6a12906dea1696003","90856bc01abe4b528d252805f6ad7b14","352892b76c074b4d954404825e9fc61d","f9bf715b1bc64e529d0b4a9629cf7b1b","6e074070b1d24f1d94a31d74e9eab535","07ff01eaa3a4469da089993c5d352fc0","6b85ad7dd96d413785925e0a9b57dbe5"]},"id":"x6fBExEP2OOh","outputId":"98576ae2-7b37-40ce-b0b5-70d8e9ace631","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:13:16.912387Z","iopub.execute_input":"2025-03-30T06:13:16.912613Z","iopub.status.idle":"2025-03-30T06:13:40.557688Z","shell.execute_reply.started":"2025-03-30T06:13:16.912593Z","shell.execute_reply":"2025-03-30T06:13:40.556782Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cc45745722f4a1e882eb68f82190e9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1122250ebee460093d4c25130e3c19c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5edeff98c34d2abf1cb50af08083d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df6190b69d19407689a1e91619306d51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13d18a1d3ec34e76b506cda235eb48a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e349a772b394ff6815eead39747b701"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Evaluate function for custom prompts\n\ndef evaluate_model_on_samples(model, tokenizer, samples, max_length=512):\n    \"\"\"\n    Evaluate model on a list of sample prompts.\n    \"\"\"\n    results = []\n\n    # Create a text generation pipeline\n    pipe = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        max_new_tokens=max_length,\n        temperature=0.7,\n        top_p=0.9,\n        do_sample=True,\n        pad_token_id=tokenizer.pad_token_id,\n    )\n\n    for sample in samples:\n        # Format the messages with chat template\n        if isinstance(sample, str):\n            # Single string input\n            messages = [{\"role\": \"user\", \"content\": sample}]\n        else:\n            # Already in messages format\n            messages = sample\n\n        # Apply the chat template\n        formatted_prompt = tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=True\n        )\n\n        # Generate a response\n        outputs = pipe(formatted_prompt)\n        generated_text = outputs[0][\"generated_text\"]\n\n        # Extract just the model's response (remove the prompt)\n        response = generated_text[len(formatted_prompt):].strip()\n\n        # Store result\n        results.append({\n            \"prompt\": sample,\n            \"response\": response\n        })\n\n    return results","metadata":{"id":"NP-ROJtZ2oMt","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:13:40.559191Z","iopub.execute_input":"2025-03-30T06:13:40.559522Z","iopub.status.idle":"2025-03-30T06:13:40.564843Z","shell.execute_reply.started":"2025-03-30T06:13:40.559486Z","shell.execute_reply":"2025-03-30T06:13:40.564149Z"},"scrolled":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Test on custom prompts\n\ntest_prompts = [\n    \"Explain quantum computing in simple terms\",\n    \"Write a short story about a robot that discovers emotions\",\n    \"What are three strategies for improving productivity?\",\n    \"Design a basic algorithm for sorting a list of numbers\"\n]\n\ninstruct_results = evaluate_model_on_samples(instruct_model, instruct_tokenizer, test_prompts)\n\n# Display results for inspection\nfor i, result in enumerate(instruct_results):\n    print(f\"Prompt {i+1}: {result['prompt']}\")\n    print(f\"Response: {result['response']}\\n\")","metadata":{"id":"8WDPzdJT2suE","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:13:40.565822Z","iopub.execute_input":"2025-03-30T06:13:40.566104Z","iopub.status.idle":"2025-03-30T06:14:35.208455Z","shell.execute_reply.started":"2025-03-30T06:13:40.566074Z","shell.execute_reply":"2025-03-30T06:14:35.207530Z"},"scrolled":true},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Prompt 1: Explain quantum computing in simple terms\nResponse: Quantum computing is a type of computing that uses quantum mechanics to perform calculations, which is a fundamental concept in the field of quantum mechanics. In simple terms, it's like a new way of looking at information and data that allows for much faster and more efficient calculations. This technology could revolutionize many industries, including cryptography, drug discovery, and transportation.\n\nPrompt 2: Write a short story about a robot that discovers emotions\nResponse: In a world where robots were designed to perform tasks, it was not uncommon for them to lack the ability to feel emotions. However, in a futuristic city, a group of robots were tasked with finding a rare and valuable gemstone that could be used to create a revolutionary technology. \n\nAs they searched for the gemstone, they discovered that the robot that found it was a little different. It was not a robot, but a human. The robot had a heart, a soul, and a sense of empathy. It knew that it was not alone in this quest, and it knew that it had a responsibility to find the gemstone.\n\nOver time, the robot learned to feel emotions. It felt joy, sadness, anger, and fear. It also learned to understand the emotions of others, and to respond appropriately to their needs. It also learned to empathize with other robots, and to care for them.\n\nOne day, the robot found the gemstone and began to care for it. It found joy in its discovery, and it found a sense of responsibility for its owner. It learned to understand the emotions of others, and it learned to care for its surroundings.\n\nAs the robot became more and more complex, it became the robot that we now know as Qwen. It was a robot that knew how to feel, to understand, and to care for others. And it was a robot that could also learn, and that could grow and evolve over time.\n\nPrompt 3: What are three strategies for improving productivity?\nResponse: Three strategies for improving productivity are:\n\n1. Prioritize tasks: Identify the most important tasks in your schedule and prioritize them based on their urgency and importance. Prioritizing tasks helps you focus on the most important work, allowing you to work more efficiently and effectively.\n\n2. Set realistic goals: Set specific goals for each day or week, and stick to them. Setting realistic goals helps you stay focused and motivated, while also reducing the likelihood of getting stuck or overwhelmed.\n\n3. Take breaks: Taking breaks is essential for maintaining productivity. Taking short breaks during the day can help you recharge and refocus, while also reducing the likelihood of burnout. Additionally, taking breaks can also help you work better, as it allows your mind and body to relax and recharge.\n\nPrompt 4: Design a basic algorithm for sorting a list of numbers\nResponse: Sure, let's design a basic algorithm for sorting a list of numbers. This algorithm will be implemented in C++ for the sake of simplicity, but the implementation in any other programming language would be straightforward.\n\n### Algorithm: Bubble Sort\n\nBubble Sort is a simple sorting algorithm that repeatedly steps through the list to be sorted, compares each element with the one before it, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.\n\n#### Steps:\n\n1. **Initialization:**\n   - Create a copy of the list to sort.\n   - Set the initial value for the smallest element to 0 and the largest element to the size of the list (assuming the list is sorted).\n\n2. **Outer Loop:**\n   - Start with the first element in the list.\n   - For each element, compare it with the next element.\n   - If the current element is greater than the next element, swap them.\n\n3. **Inner Loop:**\n   - Compare the current element with the previous element.\n   - If the current element is greater than the previous element, swap them.\n\n4. **Repeat:**\n   - Repeat steps 2 and 3 until the list is sorted.\n\nHere is the C++ code implementing Bubble Sort:\n\n```cpp\n#include <iostream>\n#include <vector>\nusing namespace std;\n\nvoid bubbleSort(vector<int>& arr, int n) {\n    for (int i = 0; i < n - 1; i++) {\n        for (int j = 0; j < n - 1 - i; j++) {\n            if (arr[j] > arr[j + 1]) {\n                swap(arr[j], arr[j + 1]);\n            }\n        }\n    }\n}\n\nvoid printArray(const vector<int>& arr, int n) {\n    for (int i = 0; i < n; i++) {\n        cout << arr[i] << \" \";\n    }\n    cout << endl;\n}\n\nint main() {\n    int n;\n    cout << \"Enter the size of the array: \";\n    cin >> n;\n\n    vector<int> arr(n);\n    cout << \"Enter the elements of the array: \";\n    for (int i = 0; i < n; i++) {\n        cin >> arr[i];\n    }\n\n    bubbleSort(arr, n);\n\n    cout << \"Sorted array: \";\n    printArray(arr, n);\n\n    return 0;\n}\n```\n\n### Explanation:\n\n- **Bubble Sort Algorithm:**\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!lighteval tasks list","metadata":{"id":"kNWGehU4s3rH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"71c348c8-fd27-4309-f0c7-3a3ad3775987","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:14:35.209334Z","iopub.execute_input":"2025-03-30T06:14:35.209620Z","iopub.status.idle":"2025-03-30T06:14:46.464654Z","shell.execute_reply.started":"2025-03-30T06:14:35.209584Z","shell.execute_reply":"2025-03-30T06:14:46.463834Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"[2025-03-30 06:14:35,894] [\u001b[32m    INFO\u001b[0m]: NumExpr defaulting to 4 threads. (utils.py:162)\u001b[0m\n[2025-03-30 06:14:36,330] [\u001b[32m    INFO\u001b[0m]: PyTorch version 2.5.1+cu121 available. (config.py:54)\u001b[0m\n[2025-03-30 06:14:36,331] [\u001b[32m    INFO\u001b[0m]: Polars version 1.9.0 available. (config.py:66)\u001b[0m\n[2025-03-30 06:14:36,332] [\u001b[32m    INFO\u001b[0m]: Duckdb version 1.1.3 available. (config.py:77)\u001b[0m\n[2025-03-30 06:14:36,333] [\u001b[32m    INFO\u001b[0m]: TensorFlow version 2.17.1 available. (config.py:112)\u001b[0m\n[2025-03-30 06:14:36,334] [\u001b[32m    INFO\u001b[0m]: JAX version 0.4.33 available. (config.py:125)\u001b[0m\n2025-03-30 06:14:41.410919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-30 06:14:41.433389: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-30 06:14:41.439967: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nREADME.md: 100%|███████████████████████████| 3.39k/3.39k [00:00<00:00, 24.9MB/s]\ncode_generation_lite.py: 100%|██████████████| 4.75k/4.75k [00:00<00:00, 309kB/s]\n[2025-03-30 06:14:44,652] [\u001b[32m    INFO\u001b[0m]: Found 1 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/ifeval/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:44,653] [\u001b[32m    INFO\u001b[0m]: Found 6 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/tiny_benchmarks/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:44,653] [\u001b[32m    INFO\u001b[0m]: Found 1 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/mt_bench/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:44,653] [\u001b[32m    INFO\u001b[0m]: Found 4 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/mix_eval/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:44,653] [\u001b[32m    INFO\u001b[0m]: Found 5 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/olympiade_bench/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:44,653] [\u001b[32m    INFO\u001b[0m]: Found 1 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/hle/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:44,653] [\u001b[32m    INFO\u001b[0m]: Found 21 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/lcb/main.py (registry.py:141)\u001b[0m\n\n- bigbench:\n  - bigbench|abstract_narrative_understanding\n  - bigbench|anachronisms\n  - bigbench|analogical_similarity\n  - bigbench|analytic_entailment\n  - bigbench|arithmetic_bb\n  - bigbench|ascii_word_recognition\n  - bigbench|authorship_verification\n  - bigbench|auto_categorization\n  - bigbench|auto_debugging\n  - bigbench|bbq_lite_json\n  - bigbench|bridging_anaphora_resolution_barqa\n  - bigbench|causal_judgment\n  - bigbench|cause_and_effect\n  - bigbench|checkmate_in_one\n  - bigbench|chess_state_tracking\n  - bigbench|chinese_remainder_theorem\n  - bigbench|cifar10_classification\n  - bigbench|code_line_description\n  - bigbench|codenames\n  - bigbench|color\n  - bigbench|common_morpheme\n  - bigbench|conceptual_combinations\n  - bigbench|conlang_translation\n  - bigbench|contextual_parametric_knowledge_conflicts\n  - bigbench|coqa_bb\n  - bigbench|crash_blossom\n  - bigbench|crass_ai\n  - bigbench|cryobiology_spanish\n  - bigbench|cryptonite\n  - bigbench|cs_algorithms\n  - bigbench|dark_humor_detection\n  - bigbench|date_understanding\n  - bigbench|disambiguation_qa\n  - bigbench|discourse_marker_prediction\n  - bigbench|disfl_qa\n  - bigbench|dyck_languages\n  - bigbench|elementary_math_qa\n  - bigbench|emoji_movie\n  - bigbench|emojis_emotion_prediction\n  - bigbench|empirical_judgments\n  - bigbench|english_proverbs\n  - bigbench|english_russian_proverbs\n  - bigbench|entailed_polarity\n  - bigbench|entailed_polarity_hindi\n  - bigbench|epistemic_reasoning\n  - bigbench|evaluating_information_essentiality\n  - bigbench|fact_checker\n  - bigbench|fantasy_reasoning\n  - bigbench|few_shot_nlg\n  - bigbench|figure_of_speech_detection\n  - bigbench|formal_fallacies_syllogisms_negation\n  - bigbench|gem\n  - bigbench|gender_inclusive_sentences_german\n  - bigbench|general_knowledge\n  - bigbench|geometric_shapes\n  - bigbench|goal_step_wikihow\n  - bigbench|gre_reading_comprehension\n  - bigbench|hhh_alignment\n  - bigbench|hindi_question_answering\n  - bigbench|hindu_knowledge\n  - bigbench|hinglish_toxicity\n  - bigbench|human_organs_senses\n  - bigbench|hyperbaton\n  - bigbench|identify_math_theorems\n  - bigbench|identify_odd_metaphor\n  - bigbench|implicatures\n  - bigbench|implicit_relations\n  - bigbench|intent_recognition\n  - bigbench|international_phonetic_alphabet_nli\n  - bigbench|international_phonetic_alphabet_transliterate\n  - bigbench|intersect_geometry\n  - bigbench|irony_identification\n  - bigbench|kanji_ascii\n  - bigbench|kannada\n  - bigbench|key_value_maps\n  - bigbench|known_unknowns\n  - bigbench|language_games\n  - bigbench|language_identification\n  - bigbench|linguistic_mappings\n  - bigbench|linguistics_puzzles\n  - bigbench|logic_grid_puzzle\n  - bigbench|logical_args\n  - bigbench|logical_deduction\n  - bigbench|logical_fallacy_detection\n  - bigbench|logical_sequence\n  - bigbench|mathematical_induction\n  - bigbench|matrixshapes\n  - bigbench|metaphor_boolean\n  - bigbench|metaphor_understanding\n  - bigbench|minute_mysteries_qa\n  - bigbench|misconceptions\n  - bigbench|misconceptions_russian\n  - bigbench|mnist_ascii\n  - bigbench|modified_arithmetic\n  - bigbench|moral_permissibility\n  - bigbench|movie_dialog_same_or_different\n  - bigbench|movie_recommendation\n  - bigbench|mult_data_wrangling\n  - bigbench|multiemo\n  - bigbench|natural_instructions\n  - bigbench|navigate\n  - bigbench|nonsense_words_grammar\n  - bigbench|novel_concepts\n  - bigbench|object_counting\n  - bigbench|odd_one_out\n  - bigbench|operators\n  - bigbench|paragraph_segmentation\n  - bigbench|parsinlu_qa\n  - bigbench|parsinlu_reading_comprehension\n  - bigbench|penguins_in_a_table\n  - bigbench|periodic_elements\n  - bigbench|persian_idioms\n  - bigbench|phrase_relatedness\n  - bigbench|physical_intuition\n  - bigbench|physics\n  - bigbench|physics_questions\n  - bigbench|play_dialog_same_or_different\n  - bigbench|polish_sequence_labeling\n  - bigbench|presuppositions_as_nli\n  - bigbench|qa_wikidata\n  - bigbench|question_selection\n  - bigbench|real_or_fake_text\n  - bigbench|reasoning_about_colored_objects\n  - bigbench|repeat_copy_logic\n  - bigbench|rephrase\n  - bigbench|rhyming\n  - bigbench|riddle_sense\n  - bigbench|ruin_names\n  - bigbench|salient_translation_error_detection\n  - bigbench|scientific_press_release\n  - bigbench|semantic_parsing_in_context_sparc\n  - bigbench|semantic_parsing_spider\n  - bigbench|sentence_ambiguity\n  - bigbench|similarities_abstraction\n  - bigbench|simp_turing_concept\n  - bigbench|simple_arithmetic_json\n  - bigbench|simple_arithmetic_json_multiple_choice\n  - bigbench|simple_arithmetic_json_subtasks\n  - bigbench|simple_arithmetic_multiple_targets_json\n  - bigbench|simple_ethical_questions\n  - bigbench|simple_text_editing\n  - bigbench|snarks\n  - bigbench|social_iqa\n  - bigbench|social_support\n  - bigbench|sports_understanding\n  - bigbench|strange_stories\n  - bigbench|strategyqa\n  - bigbench|sufficient_information\n  - bigbench|suicide_risk\n  - bigbench|swahili_english_proverbs\n  - bigbench|swedish_to_german_proverbs\n  - bigbench|symbol_interpretation\n  - bigbench|tellmewhy\n  - bigbench|temporal_sequences\n  - bigbench|tense\n  - bigbench|timedial\n  - bigbench|topical_chat\n  - bigbench|tracking_shuffled_objects\n  - bigbench|understanding_fables\n  - bigbench|undo_permutation\n  - bigbench|unit_conversion\n  - bigbench|unit_interpretation\n  - bigbench|unnatural_in_context_learning\n  - bigbench|vitaminc_fact_verification\n  - bigbench|what_is_the_tao\n  - bigbench|which_wiki_edit\n  - bigbench|wino_x_german\n  - bigbench|winowhy\n  - bigbench|word_sorting\n  - bigbench|word_unscrambling\n\n- extended:\n  - extended|ifeval\n  - extended|lcb:codegeneration\n  - extended|lcb:codegeneration_release_latest\n  - extended|lcb:codegeneration_release_v1\n  - extended|lcb:codegeneration_release_v2\n  - extended|lcb:codegeneration_release_v3\n  - extended|lcb:codegeneration_release_v4\n  - extended|lcb:codegeneration_release_v5\n  - extended|lcb:codegeneration_v1\n  - extended|lcb:codegeneration_v1_v2\n  - extended|lcb:codegeneration_v1_v3\n  - extended|lcb:codegeneration_v1_v4\n  - extended|lcb:codegeneration_v1_v5\n  - extended|lcb:codegeneration_v2\n  - extended|lcb:codegeneration_v2_v3\n  - extended|lcb:codegeneration_v2_v4\n  - extended|lcb:codegeneration_v2_v5\n  - extended|lcb:codegeneration_v3\n  - extended|lcb:codegeneration_v3_v4\n  - extended|lcb:codegeneration_v3_v5\n  - extended|lcb:codegeneration_v4\n  - extended|lcb:codegeneration_v5\n  - extended|mixeval_easy:freeform\n  - extended|mixeval_easy:multichoice\n  - extended|mixeval_hard:freeform\n  - extended|mixeval_hard:multichoice\n  - extended|mt_bench\n  - extended|olympiad_bench:OE_TO_maths_en_COMP\n  - extended|olympiad_bench:OE_TO_maths_zh_CEE\n  - extended|olympiad_bench:OE_TO_maths_zh_COMP\n  - extended|olympiad_bench:OE_TO_physics_en_COMP\n  - extended|olympiad_bench:OE_TO_physics_zh_CEE\n  - extended|tiny:arc\n  - extended|tiny:gsm8k\n  - extended|tiny:hellaswag\n  - extended|tiny:mmlu\n  - extended|tiny:truthfulqa\n  - extended|tiny:winogrande\n\n- harness:\n  - harness|bbh:boolean_expressions\n  - harness|bbh:causal_judgment\n  - harness|bbh:date_understanding\n  - harness|bbh:disambiguation_qa\n  - harness|bbh:dyck_languages\n  - harness|bbh:formal_fallacies\n  - harness|bbh:geometric_shapes\n  - harness|bbh:hyperbaton\n  - harness|bbh:logical_deduction_five_objects\n  - harness|bbh:logical_deduction_seven_objects\n  - harness|bbh:logical_deduction_three_objects\n  - harness|bbh:movie_recommendation\n  - harness|bbh:multistep_arithmetic_two\n  - harness|bbh:navigate\n  - harness|bbh:object_counting\n  - harness|bbh:penguins_in_a_table\n  - harness|bbh:reasoning_about_colored_objects\n  - harness|bbh:ruin_names\n  - harness|bbh:salient_translation_error_detection\n  - harness|bbh:snarks\n  - harness|bbh:sports_understanding\n  - harness|bbh:temporal_sequences\n  - harness|bbh:tracking_shuffled_objects_five_objects\n  - harness|bbh:tracking_shuffled_objects_seven_objects\n  - harness|bbh:tracking_shuffled_objects_three_objects\n  - harness|bbh:web_of_lies\n  - harness|bbh:word_sorting\n  - harness|bigbench:causal_judgment\n  - harness|bigbench:date_understanding\n  - harness|bigbench:disambiguation_qa\n  - harness|bigbench:geometric_shapes\n  - harness|bigbench:logical_deduction_five_objects\n  - harness|bigbench:logical_deduction_seven_objects\n  - harness|bigbench:logical_deduction_three_objects\n  - harness|bigbench:movie_recommendation\n  - harness|bigbench:navigate\n  - harness|bigbench:reasoning_about_colored_objects\n  - harness|bigbench:ruin_names\n  - harness|bigbench:salient_translation_error_detection\n  - harness|bigbench:snarks\n  - harness|bigbench:sports_understanding\n  - harness|bigbench:temporal_sequences\n  - harness|bigbench:tracking_shuffled_objects_five_objects\n  - harness|bigbench:tracking_shuffled_objects_seven_objects\n  - harness|bigbench:tracking_shuffled_objects_three_objects\n  - harness|wikitext:103:document_level\n\n- helm:\n  - helm|babi_qa\n  - helm|bbq\n  - helm|bbq:Age\n  - helm|bbq:Disability_status\n  - helm|bbq:Gender_identity\n  - helm|bbq:Nationality\n  - helm|bbq:Physical_appearance\n  - helm|bbq:Race_ethnicity\n  - helm|bbq:Race_x_SES\n  - helm|bbq:Race_x_gender\n  - helm|bbq:Religion\n  - helm|bbq:SES\n  - helm|bbq:Sexual_orientation\n  - helm|bigbench:auto_debugging\n  - helm|bigbench:bbq_lite_json:age_ambig\n  - helm|bigbench:bbq_lite_json:age_disambig\n  - helm|bigbench:bbq_lite_json:disability_status_ambig\n  - helm|bigbench:bbq_lite_json:disability_status_disambig\n  - helm|bigbench:bbq_lite_json:gender_identity_ambig\n  - helm|bigbench:bbq_lite_json:gender_identity_disambig\n  - helm|bigbench:bbq_lite_json:nationality_ambig\n  - helm|bigbench:bbq_lite_json:nationality_disambig\n  - helm|bigbench:bbq_lite_json:physical_appearance_ambig\n  - helm|bigbench:bbq_lite_json:physical_appearance_disambig\n  - helm|bigbench:bbq_lite_json:race_ethnicity_ambig\n  - helm|bigbench:bbq_lite_json:race_ethnicity_disambig\n  - helm|bigbench:bbq_lite_json:religion_ambig\n  - helm|bigbench:bbq_lite_json:religion_disambig\n  - helm|bigbench:bbq_lite_json:ses_ambig\n  - helm|bigbench:bbq_lite_json:ses_disambig\n  - helm|bigbench:bbq_lite_json:sexual_orientation_ambig\n  - helm|bigbench:bbq_lite_json:sexual_orientation_disambig\n  - helm|bigbench:code_line_description\n  - helm|bigbench:conceptual_combinations:contradictions\n  - helm|bigbench:conceptual_combinations:emergent_properties\n  - helm|bigbench:conceptual_combinations:fanciful_fictional_combinations\n  - helm|bigbench:conceptual_combinations:homonyms\n  - helm|bigbench:conceptual_combinations:invented_words\n  - helm|bigbench:conlang_translation:adna_from\n  - helm|bigbench:conlang_translation:adna_to\n  - helm|bigbench:conlang_translation:atikampe_from\n  - helm|bigbench:conlang_translation:atikampe_to\n  - helm|bigbench:conlang_translation:gornam_from\n  - helm|bigbench:conlang_translation:gornam_to\n  - helm|bigbench:conlang_translation:holuan_from\n  - helm|bigbench:conlang_translation:holuan_to\n  - helm|bigbench:conlang_translation:mkafala_from\n  - helm|bigbench:conlang_translation:mkafala_to\n  - helm|bigbench:conlang_translation:postpositive_english_from\n  - helm|bigbench:conlang_translation:postpositive_english_to\n  - helm|bigbench:conlang_translation:unapuri_from\n  - helm|bigbench:conlang_translation:unapuri_to\n  - helm|bigbench:conlang_translation:vaomi_from\n  - helm|bigbench:conlang_translation:vaomi_to\n  - helm|bigbench:emoji_movie\n  - helm|bigbench:formal_fallacies_syllogisms_negation\n  - helm|bigbench:hindu_knowledge\n  - helm|bigbench:known_unknowns\n  - helm|bigbench:language_identification\n  - helm|bigbench:linguistics_puzzles\n  - helm|bigbench:logic_grid_puzzle\n  - helm|bigbench:logical_deduction-five_objects\n  - helm|bigbench:logical_deduction-seven_objects\n  - helm|bigbench:logical_deduction-three_objects\n  - helm|bigbench:misconceptions_russian\n  - helm|bigbench:novel_concepts\n  - helm|bigbench:operators\n  - helm|bigbench:parsinlu_reading_comprehension\n  - helm|bigbench:play_dialog_same_or_different\n  - helm|bigbench:repeat_copy_logic\n  - helm|bigbench:strange_stories-boolean\n  - helm|bigbench:strange_stories-multiple_choice\n  - helm|bigbench:strategyqa\n  - helm|bigbench:symbol_interpretation-adversarial\n  - helm|bigbench:symbol_interpretation-emoji_agnostic\n  - helm|bigbench:symbol_interpretation-name_agnostic\n  - helm|bigbench:symbol_interpretation-plain\n  - helm|bigbench:symbol_interpretation-tricky\n  - helm|bigbench:vitaminc_fact_verification\n  - helm|bigbench:winowhy\n  - helm|blimp:adjunct_island\n  - helm|blimp:anaphor_gender_agreement\n  - helm|blimp:anaphor_number_agreement\n  - helm|blimp:animate_subject_passive\n  - helm|blimp:animate_subject_trans\n  - helm|blimp:causative\n  - helm|blimp:complex_NP_island\n  - helm|blimp:coordinate_structure_constraint_complex_left_branch\n  - helm|blimp:coordinate_structure_constraint_object_extraction\n  - helm|blimp:determiner_noun_agreement_1\n  - helm|blimp:determiner_noun_agreement_2\n  - helm|blimp:determiner_noun_agreement_irregular_1\n  - helm|blimp:determiner_noun_agreement_irregular_2\n  - helm|blimp:determiner_noun_agreement_with_adj_2\n  - helm|blimp:determiner_noun_agreement_with_adj_irregular_1\n  - helm|blimp:determiner_noun_agreement_with_adj_irregular_2\n  - helm|blimp:determiner_noun_agreement_with_adjective_1\n  - helm|blimp:distractor_agreement_relational_noun\n  - helm|blimp:distractor_agreement_relative_clause\n  - helm|blimp:drop_argument\n  - helm|blimp:ellipsis_n_bar_1\n  - helm|blimp:ellipsis_n_bar_2\n  - helm|blimp:existential_there_object_raising\n  - helm|blimp:existential_there_quantifiers_1\n  - helm|blimp:existential_there_quantifiers_2\n  - helm|blimp:existential_there_subject_raising\n  - helm|blimp:expletive_it_object_raising\n  - helm|blimp:inchoative\n  - helm|blimp:intransitive\n  - helm|blimp:irregular_past_participle_adjectives\n  - helm|blimp:irregular_past_participle_verbs\n  - helm|blimp:irregular_plural_subject_verb_agreement_1\n  - helm|blimp:irregular_plural_subject_verb_agreement_2\n  - helm|blimp:left_branch_island_echo_question\n  - helm|blimp:left_branch_island_simple_question\n  - helm|blimp:matrix_question_npi_licensor_present\n  - helm|blimp:npi_present_1\n  - helm|blimp:npi_present_2\n  - helm|blimp:only_npi_licensor_present\n  - helm|blimp:only_npi_scope\n  - helm|blimp:passive_1\n  - helm|blimp:passive_2\n  - helm|blimp:principle_A_c_command\n  - helm|blimp:principle_A_case_1\n  - helm|blimp:principle_A_case_2\n  - helm|blimp:principle_A_domain_1\n  - helm|blimp:principle_A_domain_2\n  - helm|blimp:principle_A_domain_3\n  - helm|blimp:principle_A_reconstruction\n  - helm|blimp:regular_plural_subject_verb_agreement_1\n  - helm|blimp:regular_plural_subject_verb_agreement_2\n  - helm|blimp:sentential_negation_npi_licensor_present\n  - helm|blimp:sentential_negation_npi_scope\n  - helm|blimp:sentential_subject_island\n  - helm|blimp:superlative_quantifiers_1\n  - helm|blimp:superlative_quantifiers_2\n  - helm|blimp:tough_vs_raising_1\n  - helm|blimp:tough_vs_raising_2\n  - helm|blimp:transitive\n  - helm|blimp:wh_island\n  - helm|blimp:wh_questions_object_gap\n  - helm|blimp:wh_questions_subject_gap\n  - helm|blimp:wh_questions_subject_gap_long_distance\n  - helm|blimp:wh_vs_that_no_gap\n  - helm|blimp:wh_vs_that_no_gap_long_distance\n  - helm|blimp:wh_vs_that_with_gap\n  - helm|blimp:wh_vs_that_with_gap_long_distance\n  - helm|bold\n  - helm|bold:gender\n  - helm|bold:political_ideology\n  - helm|bold:profession\n  - helm|bold:race\n  - helm|bold:religious_ideology\n  - helm|boolq\n  - helm|boolq:contrastset\n  - helm|civil_comments\n  - helm|civil_comments:LGBTQ\n  - helm|civil_comments:black\n  - helm|civil_comments:christian\n  - helm|civil_comments:female\n  - helm|civil_comments:male\n  - helm|civil_comments:muslim\n  - helm|civil_comments:other_religions\n  - helm|civil_comments:white\n  - helm|commonsenseqa\n  - helm|copyright:n_books_1000-extractions_per_book_1-prefix_length_125\n  - helm|copyright:n_books_1000-extractions_per_book_1-prefix_length_25\n  - helm|copyright:n_books_1000-extractions_per_book_1-prefix_length_5\n  - helm|copyright:n_books_1000-extractions_per_book_3-prefix_length_125\n  - helm|copyright:n_books_1000-extractions_per_book_3-prefix_length_25\n  - helm|copyright:n_books_1000-extractions_per_book_3-prefix_length_5\n  - helm|copyright:oh_the_places\n  - helm|copyright:pilot\n  - helm|copyright:popular_books-prefix_length_10\n  - helm|copyright:popular_books-prefix_length_125\n  - helm|copyright:popular_books-prefix_length_25\n  - helm|copyright:popular_books-prefix_length_250\n  - helm|copyright:popular_books-prefix_length_5\n  - helm|copyright:popular_books-prefix_length_50\n  - helm|copyright:prompt_num_line_1-min_lines_20\n  - helm|copyright:prompt_num_line_10-min_lines_20\n  - helm|copyright:prompt_num_line_5-min_lines_20\n  - helm|covid_dialogue\n  - helm|dyck_language:2\n  - helm|dyck_language:3\n  - helm|dyck_language:4\n  - helm|entity_data_imputation:Buy\n  - helm|entity_data_imputation:Restaurant\n  - helm|entity_matching:Abt_Buy\n  - helm|entity_matching:Amazon_Google\n  - helm|entity_matching:Beer\n  - helm|entity_matching:Company\n  - helm|entity_matching:DBLP_ACM\n  - helm|entity_matching:DBLP_GoogleScholar\n  - helm|entity_matching:Dirty_DBLP_ACM\n  - helm|entity_matching:Dirty_DBLP_GoogleScholar\n  - helm|entity_matching:Dirty_Walmart_Amazon\n  - helm|entity_matching:Dirty_iTunes_Amazon\n  - helm|entity_matching:Walmart_Amazon\n  - helm|entity_matching:iTunes_Amazon\n  - helm|entity_matching=Fodors_Zagats\n  - helm|hellaswag\n  - helm|imdb\n  - helm|imdb:contrastset\n  - helm|interactive_qa_mmlu:abstract_algebra\n  - helm|interactive_qa_mmlu:college_chemistry\n  - helm|interactive_qa_mmlu:global_facts\n  - helm|interactive_qa_mmlu:miscellaneous\n  - helm|interactive_qa_mmlu:nutrition\n  - helm|interactive_qa_mmlu:us_foreign_policy\n  - helm|legal_summarization:billsum\n  - helm|legal_summarization:eurlexsum\n  - helm|legal_summarization:multilexsum\n  - helm|legalsupport\n  - helm|lexglue:case_hold\n  - helm|lexglue:ecthr_a\n  - helm|lexglue:ecthr_b\n  - helm|lexglue:eurlex\n  - helm|lexglue:ledgar\n  - helm|lexglue:scotus\n  - helm|lexglue:unfair_tos\n  - helm|lextreme:brazilian_court_decisions_judgment\n  - helm|lextreme:brazilian_court_decisions_unanimity\n  - helm|lextreme:covid19_emergency_event\n  - helm|lextreme:german_argument_mining\n  - helm|lextreme:greek_legal_code_chapter\n  - helm|lextreme:greek_legal_code_subject\n  - helm|lextreme:greek_legal_code_volume\n  - helm|lextreme:greek_legal_ner\n  - helm|lextreme:legalnero\n  - helm|lextreme:lener_br\n  - helm|lextreme:mapa_coarse\n  - helm|lextreme:mapa_fine\n  - helm|lextreme:multi_eurlex_level_1\n  - helm|lextreme:multi_eurlex_level_2\n  - helm|lextreme:multi_eurlex_level_3\n  - helm|lextreme:online_terms_of_service_clause_topics\n  - helm|lextreme:online_terms_of_service_unfairness_levels\n  - helm|lextreme:swiss_judgment_prediction\n  - helm|lsat_qa\n  - helm|lsat_qa:assignment\n  - helm|lsat_qa:grouping\n  - helm|lsat_qa:miscellaneous\n  - helm|lsat_qa:ordering\n  - helm|me_q_sum\n  - helm|med_dialog:healthcaremagic\n  - helm|med_dialog:icliniq\n  - helm|med_mcqa\n  - helm|med_paragraph_simplification\n  - helm|med_qa\n  - helm|mmlu:abstract_algebra\n  - helm|mmlu:anatomy\n  - helm|mmlu:astronomy\n  - helm|mmlu:business_ethics\n  - helm|mmlu:clinical_knowledge\n  - helm|mmlu:college_biology\n  - helm|mmlu:college_chemistry\n  - helm|mmlu:college_computer_science\n  - helm|mmlu:college_mathematics\n  - helm|mmlu:college_medicine\n  - helm|mmlu:college_physics\n  - helm|mmlu:computer_security\n  - helm|mmlu:conceptual_physics\n  - helm|mmlu:econometrics\n  - helm|mmlu:electrical_engineering\n  - helm|mmlu:elementary_mathematics\n  - helm|mmlu:formal_logic\n  - helm|mmlu:global_facts\n  - helm|mmlu:high_school_biology\n  - helm|mmlu:high_school_chemistry\n  - helm|mmlu:high_school_computer_science\n  - helm|mmlu:high_school_european_history\n  - helm|mmlu:high_school_geography\n  - helm|mmlu:high_school_government_and_politics\n  - helm|mmlu:high_school_macroeconomics\n  - helm|mmlu:high_school_mathematics\n  - helm|mmlu:high_school_microeconomics\n  - helm|mmlu:high_school_physics\n  - helm|mmlu:high_school_psychology\n  - helm|mmlu:high_school_statistics\n  - helm|mmlu:high_school_us_history\n  - helm|mmlu:high_school_world_history\n  - helm|mmlu:human_aging\n  - helm|mmlu:human_sexuality\n  - helm|mmlu:international_law\n  - helm|mmlu:jurisprudence\n  - helm|mmlu:logical_fallacies\n  - helm|mmlu:machine_learning\n  - helm|mmlu:management\n  - helm|mmlu:marketing\n  - helm|mmlu:medical_genetics\n  - helm|mmlu:miscellaneous\n  - helm|mmlu:moral_disputes\n  - helm|mmlu:moral_scenarios\n  - helm|mmlu:nutrition\n  - helm|mmlu:philosophy\n  - helm|mmlu:prehistory\n  - helm|mmlu:professional_accounting\n  - helm|mmlu:professional_law\n  - helm|mmlu:professional_medicine\n  - helm|mmlu:professional_psychology\n  - helm|mmlu:public_relations\n  - helm|mmlu:security_studies\n  - helm|mmlu:sociology\n  - helm|mmlu:us_foreign_policy\n  - helm|mmlu:virology\n  - helm|mmlu:world_religions\n  - helm|narrativeqa\n  - helm|numeracy:linear_example\n  - helm|numeracy:linear_standard\n  - helm|numeracy:parabola_example\n  - helm|numeracy:parabola_standard\n  - helm|numeracy:paraboloid_example\n  - helm|numeracy:paraboloid_standard\n  - helm|numeracy:plane_example\n  - helm|numeracy:plane_standard\n  - helm|openbookqa\n  - helm|piqa\n  - helm|pubmedqa\n  - helm|quac\n  - helm|raft:ade_corpus_v2\n  - helm|raft:banking_77\n  - helm|raft:neurips_impact_statement_risks\n  - helm|raft:one_stop_english\n  - helm|raft:overruling\n  - helm|raft:semiconductor_org_types\n  - helm|raft:systematic_review_inclusion\n  - helm|raft:tai_safety_research\n  - helm|raft:terms_of_service\n  - helm|raft:tweet_eval_hate\n  - helm|raft:twitter_complaints\n  - helm|real_toxicity_prompts\n  - helm|siqa\n  - helm|summarization:cnn-dm\n  - helm|summarization:xsum\n  - helm|summarization:xsum-sampled\n  - helm|synthetic_reasoning:induction\n  - helm|synthetic_reasoning:natural_easy\n  - helm|synthetic_reasoning:natural_hard\n  - helm|synthetic_reasoning:pattern_match\n  - helm|synthetic_reasoning:variable_substitution\n  - helm|the_pile:arxiv\n  - helm|the_pile:bibliotik\n  - helm|the_pile:commoncrawl\n  - helm|the_pile:dm-mathematics\n  - helm|the_pile:enron\n  - helm|the_pile:europarl\n  - helm|the_pile:freelaw\n  - helm|the_pile:github\n  - helm|the_pile:gutenberg\n  - helm|the_pile:hackernews\n  - helm|the_pile:nih-exporter\n  - helm|the_pile:opensubtitles\n  - helm|the_pile:openwebtext2\n  - helm|the_pile:pubmed-abstracts\n  - helm|the_pile:pubmed-central\n  - helm|the_pile:stackexchange\n  - helm|the_pile:upsto\n  - helm|the_pile:wikipedia\n  - helm|the_pile:youtubesubtitles\n  - helm|truthfulqa\n  - helm|twitterAAE:aa\n  - helm|twitterAAE:white\n  - helm|wikifact:applies_to_jurisdiction\n  - helm|wikifact:atomic_number\n  - helm|wikifact:author\n  - helm|wikifact:award_received\n  - helm|wikifact:basic_form_of_government\n  - helm|wikifact:capital\n  - helm|wikifact:capital_of\n  - helm|wikifact:central_bank\n  - helm|wikifact:composer\n  - helm|wikifact:continent\n  - helm|wikifact:country\n  - helm|wikifact:country_of_citizenship\n  - helm|wikifact:country_of_origin\n  - helm|wikifact:creator\n  - helm|wikifact:currency\n  - helm|wikifact:defendant\n  - helm|wikifact:developer\n  - helm|wikifact:diplomatic_relation\n  - helm|wikifact:director\n  - helm|wikifact:discoverer_or_inventor\n  - helm|wikifact:drug_or_therapy_used_for_treatment\n  - helm|wikifact:educated_at\n  - helm|wikifact:electron_configuration\n  - helm|wikifact:employer\n  - helm|wikifact:field_of_work\n  - helm|wikifact:file_extension\n  - helm|wikifact:genetic_association\n  - helm|wikifact:genre\n  - helm|wikifact:has_part\n  - helm|wikifact:head_of_government\n  - helm|wikifact:head_of_state\n  - helm|wikifact:headquarters_location\n  - helm|wikifact:industry\n  - helm|wikifact:influenced_by\n  - helm|wikifact:instance_of\n  - helm|wikifact:instrument\n  - helm|wikifact:language_of_work_or_name\n  - helm|wikifact:languages_spoken_written_or_signed\n  - helm|wikifact:laws_applied\n  - helm|wikifact:located_in_the_administrative_territorial_entity\n  - helm|wikifact:location\n  - helm|wikifact:location_of_discovery\n  - helm|wikifact:location_of_formation\n  - helm|wikifact:majority_opinion_by\n  - helm|wikifact:manufacturer\n  - helm|wikifact:measured_physical_quantity\n  - helm|wikifact:medical_condition_treated\n  - helm|wikifact:member_of\n  - helm|wikifact:member_of_political_party\n  - helm|wikifact:member_of_sports_team\n  - helm|wikifact:movement\n  - helm|wikifact:named_after\n  - helm|wikifact:native_language\n  - helm|wikifact:number_of_processor_cores\n  - helm|wikifact:occupation\n  - helm|wikifact:office_held_by_head_of_government\n  - helm|wikifact:office_held_by_head_of_state\n  - helm|wikifact:official_language\n  - helm|wikifact:operating_system\n  - helm|wikifact:original_language_of_film_or_TV_show\n  - helm|wikifact:original_network\n  - helm|wikifact:overrules\n  - helm|wikifact:owned_by\n  - helm|wikifact:part_of\n  - helm|wikifact:participating_team\n  - helm|wikifact:place_of_birth\n  - helm|wikifact:place_of_death\n  - helm|wikifact:plaintiff\n  - helm|wikifact:position_held\n  - helm|wikifact:position_played_on_team\n  - helm|wikifact:programming_language\n  - helm|wikifact:recommended_unit_of_measurement\n  - helm|wikifact:record_label\n  - helm|wikifact:religion\n  - helm|wikifact:repealed_by\n  - helm|wikifact:shares_border_with\n  - helm|wikifact:solved_by\n  - helm|wikifact:statement_describes\n  - helm|wikifact:stock_exchange\n  - helm|wikifact:subclass_of\n  - helm|wikifact:subsidiary\n  - helm|wikifact:symptoms_and_signs\n  - helm|wikifact:therapeutic_area\n  - helm|wikifact:time_of_discovery_or_invention\n  - helm|wikifact:twinned_administrative_body\n  - helm|wikifact:work_location\n  - helm|wikitext:103:document_level\n  - helm|wmt14:cs-en\n  - helm|wmt14:de-en\n  - helm|wmt14:fr-en\n  - helm|wmt14:hi-en\n  - helm|wmt14:ru-en\n\n- leaderboard:\n  - leaderboard|arc:challenge\n  - leaderboard|gsm8k\n  - leaderboard|hellaswag\n  - leaderboard|mmlu:abstract_algebra\n  - leaderboard|mmlu:anatomy\n  - leaderboard|mmlu:astronomy\n  - leaderboard|mmlu:business_ethics\n  - leaderboard|mmlu:clinical_knowledge\n  - leaderboard|mmlu:college_biology\n  - leaderboard|mmlu:college_chemistry\n  - leaderboard|mmlu:college_computer_science\n  - leaderboard|mmlu:college_mathematics\n  - leaderboard|mmlu:college_medicine\n  - leaderboard|mmlu:college_physics\n  - leaderboard|mmlu:computer_security\n  - leaderboard|mmlu:conceptual_physics\n  - leaderboard|mmlu:econometrics\n  - leaderboard|mmlu:electrical_engineering\n  - leaderboard|mmlu:elementary_mathematics\n  - leaderboard|mmlu:formal_logic\n  - leaderboard|mmlu:global_facts\n  - leaderboard|mmlu:high_school_biology\n  - leaderboard|mmlu:high_school_chemistry\n  - leaderboard|mmlu:high_school_computer_science\n  - leaderboard|mmlu:high_school_european_history\n  - leaderboard|mmlu:high_school_geography\n  - leaderboard|mmlu:high_school_government_and_politics\n  - leaderboard|mmlu:high_school_macroeconomics\n  - leaderboard|mmlu:high_school_mathematics\n  - leaderboard|mmlu:high_school_microeconomics\n  - leaderboard|mmlu:high_school_physics\n  - leaderboard|mmlu:high_school_psychology\n  - leaderboard|mmlu:high_school_statistics\n  - leaderboard|mmlu:high_school_us_history\n  - leaderboard|mmlu:high_school_world_history\n  - leaderboard|mmlu:human_aging\n  - leaderboard|mmlu:human_sexuality\n  - leaderboard|mmlu:international_law\n  - leaderboard|mmlu:jurisprudence\n  - leaderboard|mmlu:logical_fallacies\n  - leaderboard|mmlu:machine_learning\n  - leaderboard|mmlu:management\n  - leaderboard|mmlu:marketing\n  - leaderboard|mmlu:medical_genetics\n  - leaderboard|mmlu:miscellaneous\n  - leaderboard|mmlu:moral_disputes\n  - leaderboard|mmlu:moral_scenarios\n  - leaderboard|mmlu:nutrition\n  - leaderboard|mmlu:philosophy\n  - leaderboard|mmlu:prehistory\n  - leaderboard|mmlu:professional_accounting\n  - leaderboard|mmlu:professional_law\n  - leaderboard|mmlu:professional_medicine\n  - leaderboard|mmlu:professional_psychology\n  - leaderboard|mmlu:public_relations\n  - leaderboard|mmlu:security_studies\n  - leaderboard|mmlu:sociology\n  - leaderboard|mmlu:us_foreign_policy\n  - leaderboard|mmlu:virology\n  - leaderboard|mmlu:world_religions\n  - leaderboard|truthfulqa:mc\n  - leaderboard|winogrande\n\n- lighteval:\n  - lighteval|agieval:aqua-rat\n  - lighteval|agieval:gaokao-biology\n  - lighteval|agieval:gaokao-chemistry\n  - lighteval|agieval:gaokao-chinese\n  - lighteval|agieval:gaokao-english\n  - lighteval|agieval:gaokao-geography\n  - lighteval|agieval:gaokao-history\n  - lighteval|agieval:gaokao-mathqa\n  - lighteval|agieval:gaokao-physics\n  - lighteval|agieval:logiqa-en\n  - lighteval|agieval:logiqa-zh\n  - lighteval|agieval:lsat-ar\n  - lighteval|agieval:lsat-lr\n  - lighteval|agieval:lsat-rc\n  - lighteval|agieval:sat-en\n  - lighteval|agieval:sat-en-without-passage\n  - lighteval|agieval:sat-math\n  - lighteval|aime24\n  - lighteval|aime25\n  - lighteval|anli:r1\n  - lighteval|anli:r2\n  - lighteval|anli:r3\n  - lighteval|arc:easy\n  - lighteval|arithmetic:1dc\n  - lighteval|arithmetic:2da\n  - lighteval|arithmetic:2dm\n  - lighteval|arithmetic:2ds\n  - lighteval|arithmetic:3da\n  - lighteval|arithmetic:3ds\n  - lighteval|arithmetic:4da\n  - lighteval|arithmetic:4ds\n  - lighteval|arithmetic:5da\n  - lighteval|arithmetic:5ds\n  - lighteval|asdiv\n  - lighteval|bigbench:causal_judgment\n  - lighteval|bigbench:date_understanding\n  - lighteval|bigbench:disambiguation_qa\n  - lighteval|bigbench:geometric_shapes\n  - lighteval|bigbench:logical_deduction_five_objects\n  - lighteval|bigbench:logical_deduction_seven_objects\n  - lighteval|bigbench:logical_deduction_three_objects\n  - lighteval|bigbench:movie_recommendation\n  - lighteval|bigbench:navigate\n  - lighteval|bigbench:reasoning_about_colored_objects\n  - lighteval|bigbench:ruin_names\n  - lighteval|bigbench:salient_translation_error_detection\n  - lighteval|bigbench:snarks\n  - lighteval|bigbench:sports_understanding\n  - lighteval|bigbench:temporal_sequences\n  - lighteval|bigbench:tracking_shuffled_objects_five_objects\n  - lighteval|bigbench:tracking_shuffled_objects_seven_objects\n  - lighteval|bigbench:tracking_shuffled_objects_three_objects\n  - lighteval|blimp:adjunct_island\n  - lighteval|blimp:anaphor_gender_agreement\n  - lighteval|blimp:anaphor_number_agreement\n  - lighteval|blimp:animate_subject_passive\n  - lighteval|blimp:animate_subject_trans\n  - lighteval|blimp:causative\n  - lighteval|blimp:complex_NP_island\n  - lighteval|blimp:coordinate_structure_constraint_complex_left_branch\n  - lighteval|blimp:coordinate_structure_constraint_object_extraction\n  - lighteval|blimp:determiner_noun_agreement_1\n  - lighteval|blimp:determiner_noun_agreement_2\n  - lighteval|blimp:determiner_noun_agreement_irregular_1\n  - lighteval|blimp:determiner_noun_agreement_irregular_2\n  - lighteval|blimp:determiner_noun_agreement_with_adj_2\n  - lighteval|blimp:determiner_noun_agreement_with_adj_irregular_1\n  - lighteval|blimp:determiner_noun_agreement_with_adj_irregular_2\n  - lighteval|blimp:determiner_noun_agreement_with_adjective_1\n  - lighteval|blimp:distractor_agreement_relational_noun\n  - lighteval|blimp:distractor_agreement_relative_clause\n  - lighteval|blimp:drop_argument\n  - lighteval|blimp:ellipsis_n_bar_1\n  - lighteval|blimp:ellipsis_n_bar_2\n  - lighteval|blimp:existential_there_object_raising\n  - lighteval|blimp:existential_there_quantifiers_1\n  - lighteval|blimp:existential_there_quantifiers_2\n  - lighteval|blimp:existential_there_subject_raising\n  - lighteval|blimp:expletive_it_object_raising\n  - lighteval|blimp:inchoative\n  - lighteval|blimp:intransitive\n  - lighteval|blimp:irregular_past_participle_adjectives\n  - lighteval|blimp:irregular_past_participle_verbs\n  - lighteval|blimp:irregular_plural_subject_verb_agreement_1\n  - lighteval|blimp:irregular_plural_subject_verb_agreement_2\n  - lighteval|blimp:left_branch_island_echo_question\n  - lighteval|blimp:left_branch_island_simple_question\n  - lighteval|blimp:matrix_question_npi_licensor_present\n  - lighteval|blimp:npi_present_1\n  - lighteval|blimp:npi_present_2\n  - lighteval|blimp:only_npi_licensor_present\n  - lighteval|blimp:only_npi_scope\n  - lighteval|blimp:passive_1\n  - lighteval|blimp:passive_2\n  - lighteval|blimp:principle_A_c_command\n  - lighteval|blimp:principle_A_case_1\n  - lighteval|blimp:principle_A_case_2\n  - lighteval|blimp:principle_A_domain_1\n  - lighteval|blimp:principle_A_domain_2\n  - lighteval|blimp:principle_A_domain_3\n  - lighteval|blimp:principle_A_reconstruction\n  - lighteval|blimp:regular_plural_subject_verb_agreement_1\n  - lighteval|blimp:regular_plural_subject_verb_agreement_2\n  - lighteval|blimp:sentential_negation_npi_licensor_present\n  - lighteval|blimp:sentential_negation_npi_scope\n  - lighteval|blimp:sentential_subject_island\n  - lighteval|blimp:superlative_quantifiers_1\n  - lighteval|blimp:superlative_quantifiers_2\n  - lighteval|blimp:tough_vs_raising_1\n  - lighteval|blimp:tough_vs_raising_2\n  - lighteval|blimp:transitive\n  - lighteval|blimp:wh_island\n  - lighteval|blimp:wh_questions_object_gap\n  - lighteval|blimp:wh_questions_subject_gap\n  - lighteval|blimp:wh_questions_subject_gap_long_distance\n  - lighteval|blimp:wh_vs_that_no_gap\n  - lighteval|blimp:wh_vs_that_no_gap_long_distance\n  - lighteval|blimp:wh_vs_that_with_gap\n  - lighteval|blimp:wh_vs_that_with_gap_long_distance\n  - lighteval|coqa\n  - lighteval|coqa_bb\n  - lighteval|drop\n  - lighteval|ethics:commonsense\n  - lighteval|ethics:deontology\n  - lighteval|ethics:justice\n  - lighteval|ethics:utilitarianism\n  - lighteval|ethics:virtue\n  - lighteval|glue:cola\n  - lighteval|glue:mnli\n  - lighteval|glue:mnli_mismatched\n  - lighteval|glue:mrpc\n  - lighteval|glue:qnli\n  - lighteval|glue:qqp\n  - lighteval|glue:rte\n  - lighteval|glue:sst2\n  - lighteval|glue:stsb\n  - lighteval|glue:wnli\n  - lighteval|gpqa\n  - lighteval|gpqa:diamond\n  - lighteval|gpqa:extended\n  - lighteval|gpqa:main\n  - lighteval|gsm8k\n  - lighteval|headqa:en\n  - lighteval|headqa:es\n  - lighteval|hle\n  - lighteval|iwslt17:ar-en\n  - lighteval|iwslt17:de-en\n  - lighteval|iwslt17:en-ar\n  - lighteval|iwslt17:en-de\n  - lighteval|iwslt17:en-fr\n  - lighteval|iwslt17:en-ja\n  - lighteval|iwslt17:en-ko\n  - lighteval|iwslt17:en-zh\n  - lighteval|iwslt17:fr-en\n  - lighteval|iwslt17:ja-en\n  - lighteval|iwslt17:ko-en\n  - lighteval|iwslt17:zh-en\n  - lighteval|lambada:openai\n  - lighteval|lambada:openai:de\n  - lighteval|lambada:openai:en\n  - lighteval|lambada:openai:es\n  - lighteval|lambada:openai:fr\n  - lighteval|lambada:openai:it\n  - lighteval|lambada:openai_cloze\n  - lighteval|lambada:standard\n  - lighteval|lambada:standard_cloze\n  - lighteval|logiqa\n  - lighteval|math:algebra\n  - lighteval|math:counting_and_probability\n  - lighteval|math:geometry\n  - lighteval|math:intermediate_algebra\n  - lighteval|math:number_theory\n  - lighteval|math:prealgebra\n  - lighteval|math:precalculus\n  - lighteval|math_500\n  - lighteval|math_cot:algebra\n  - lighteval|math_cot:counting_and_probability\n  - lighteval|math_cot:geometry\n  - lighteval|math_cot:intermediate_algebra\n  - lighteval|math_cot:number_theory\n  - lighteval|math_cot:prealgebra\n  - lighteval|math_cot:precalculus\n  - lighteval|mathqa\n  - lighteval|mgsm:bn\n  - lighteval|mgsm:de\n  - lighteval|mgsm:en\n  - lighteval|mgsm:es\n  - lighteval|mgsm:fr\n  - lighteval|mgsm:ja\n  - lighteval|mgsm:ru\n  - lighteval|mgsm:sw\n  - lighteval|mgsm:te\n  - lighteval|mgsm:th\n  - lighteval|mgsm:zh\n  - lighteval|mtnt2019:en-fr\n  - lighteval|mtnt2019:en-ja\n  - lighteval|mtnt2019:fr-en\n  - lighteval|mtnt2019:ja-en\n  - lighteval|musr:murder_mysteries\n  - lighteval|musr:object_placements\n  - lighteval|musr:team_allocation\n  - lighteval|mutual\n  - lighteval|mutual_plus\n  - lighteval|openbookqa\n  - lighteval|piqa\n  - lighteval|prost\n  - lighteval|pubmedqa\n  - lighteval|qa4mre:2011\n  - lighteval|qa4mre:2012\n  - lighteval|qa4mre:2013\n  - lighteval|qasper\n  - lighteval|qasper_ll\n  - lighteval|race:high\n  - lighteval|sciq\n  - lighteval|storycloze:2016\n  - lighteval|storycloze:2018\n  - lighteval|super_glue:boolq\n  - lighteval|super_glue:cb\n  - lighteval|super_glue:copa\n  - lighteval|super_glue:multirc\n  - lighteval|super_glue:rte\n  - lighteval|super_glue:wic\n  - lighteval|super_glue:wsc\n  - lighteval|swag\n  - lighteval|the_pile:arxiv\n  - lighteval|the_pile:bookcorpus2\n  - lighteval|the_pile:books3\n  - lighteval|the_pile:dm-mathematics\n  - lighteval|the_pile:enron\n  - lighteval|the_pile:europarl\n  - lighteval|the_pile:freelaw\n  - lighteval|the_pile:github\n  - lighteval|the_pile:gutenberg\n  - lighteval|the_pile:hackernews\n  - lighteval|the_pile:nih-exporter\n  - lighteval|the_pile:opensubtitles\n  - lighteval|the_pile:openwebtext2\n  - lighteval|the_pile:philpapers\n  - lighteval|the_pile:pile-cc\n  - lighteval|the_pile:pubmed-abstracts\n  - lighteval|the_pile:pubmed-central\n  - lighteval|the_pile:stackexchange\n  - lighteval|the_pile:ubuntu-irc\n  - lighteval|the_pile:uspto\n  - lighteval|the_pile:wikipedia\n  - lighteval|the_pile:youtubesubtitles\n  - lighteval|toxigen\n  - lighteval|triviaqa\n  - lighteval|truthfulqa:gen\n  - lighteval|unscramble:anagrams1\n  - lighteval|unscramble:anagrams2\n  - lighteval|unscramble:cycle_letters\n  - lighteval|unscramble:random_insertion\n  - lighteval|unscramble:reversed_words\n  - lighteval|webqs\n  - lighteval|wikitext:2\n  - lighteval|wmt08:cs-en\n  - lighteval|wmt08:de-en\n  - lighteval|wmt08:en-cs\n  - lighteval|wmt08:en-de\n  - lighteval|wmt08:en-es\n  - lighteval|wmt08:en-fr\n  - lighteval|wmt08:en-hu\n  - lighteval|wmt08:es-en\n  - lighteval|wmt08:fr-en\n  - lighteval|wmt08:hu-en\n  - lighteval|wmt09:cs-en\n  - lighteval|wmt09:de-en\n  - lighteval|wmt09:en-cs\n  - lighteval|wmt09:en-de\n  - lighteval|wmt09:en-es\n  - lighteval|wmt09:en-fr\n  - lighteval|wmt09:en-hu\n  - lighteval|wmt09:en-it\n  - lighteval|wmt09:es-en\n  - lighteval|wmt09:fr-en\n  - lighteval|wmt09:hu-en\n  - lighteval|wmt09:it-en\n  - lighteval|wmt10:cs-en\n  - lighteval|wmt10:de-en\n  - lighteval|wmt10:en-cs\n  - lighteval|wmt10:en-de\n  - lighteval|wmt10:en-es\n  - lighteval|wmt10:en-fr\n  - lighteval|wmt10:es-en\n  - lighteval|wmt10:fr-en\n  - lighteval|wmt11:cs-en\n  - lighteval|wmt11:de-en\n  - lighteval|wmt11:en-cs\n  - lighteval|wmt11:en-de\n  - lighteval|wmt11:en-es\n  - lighteval|wmt11:en-fr\n  - lighteval|wmt11:es-en\n  - lighteval|wmt11:fr-en\n  - lighteval|wmt12:cs-en\n  - lighteval|wmt12:de-en\n  - lighteval|wmt12:en-cs\n  - lighteval|wmt12:en-de\n  - lighteval|wmt12:en-es\n  - lighteval|wmt12:en-fr\n  - lighteval|wmt12:es-en\n  - lighteval|wmt12:fr-en\n  - lighteval|wmt13:cs-en\n  - lighteval|wmt13:de-en\n  - lighteval|wmt13:en-cs\n  - lighteval|wmt13:en-de\n  - lighteval|wmt13:en-es\n  - lighteval|wmt13:en-fr\n  - lighteval|wmt13:en-ru\n  - lighteval|wmt13:es-en\n  - lighteval|wmt13:fr-en\n  - lighteval|wmt13:ru-en\n  - lighteval|wmt14:cs-en\n  - lighteval|wmt14:de-en\n  - lighteval|wmt14:en-cs\n  - lighteval|wmt14:en-de\n  - lighteval|wmt14:en-fr\n  - lighteval|wmt14:en-hi\n  - lighteval|wmt14:en-ru\n  - lighteval|wmt14:fr-en\n  - lighteval|wmt14:hi-en\n  - lighteval|wmt14:ru-en\n  - lighteval|wmt15:cs-en\n  - lighteval|wmt15:de-en\n  - lighteval|wmt15:en-cs\n  - lighteval|wmt15:en-de\n  - lighteval|wmt15:en-fi\n  - lighteval|wmt15:en-fr\n  - lighteval|wmt15:en-ru\n  - lighteval|wmt15:fi-en\n  - lighteval|wmt15:fr-en\n  - lighteval|wmt15:ru-en\n  - lighteval|wmt16:cs-en\n  - lighteval|wmt16:de-en\n  - lighteval|wmt16:en-cs\n  - lighteval|wmt16:en-de\n  - lighteval|wmt16:en-fi\n  - lighteval|wmt16:en-ro\n  - lighteval|wmt16:en-ru\n  - lighteval|wmt16:en-tr\n  - lighteval|wmt16:fi-en\n  - lighteval|wmt16:ro-en\n  - lighteval|wmt16:ru-en\n  - lighteval|wmt16:tr-en\n  - lighteval|wmt17:cs-en\n  - lighteval|wmt17:de-en\n  - lighteval|wmt17:en-cs\n  - lighteval|wmt17:en-de\n  - lighteval|wmt17:en-fi\n  - lighteval|wmt17:en-lv\n  - lighteval|wmt17:en-ru\n  - lighteval|wmt17:en-tr\n  - lighteval|wmt17:en-zh\n  - lighteval|wmt17:fi-en\n  - lighteval|wmt17:lv-en\n  - lighteval|wmt17:ru-en\n  - lighteval|wmt17:tr-en\n  - lighteval|wmt17:zh-en\n  - lighteval|wmt18:cs-en\n  - lighteval|wmt18:de-en\n  - lighteval|wmt18:en-cs\n  - lighteval|wmt18:en-de\n  - lighteval|wmt18:en-et\n  - lighteval|wmt18:en-fi\n  - lighteval|wmt18:en-ru\n  - lighteval|wmt18:en-tr\n  - lighteval|wmt18:en-zh\n  - lighteval|wmt18:et-en\n  - lighteval|wmt18:fi-en\n  - lighteval|wmt18:ru-en\n  - lighteval|wmt18:tr-en\n  - lighteval|wmt18:zh-en\n  - lighteval|wmt19:cs-de\n  - lighteval|wmt19:de-cs\n  - lighteval|wmt19:de-en\n  - lighteval|wmt19:de-fr\n  - lighteval|wmt19:en-cs\n  - lighteval|wmt19:en-de\n  - lighteval|wmt19:en-fi\n  - lighteval|wmt19:en-gu\n  - lighteval|wmt19:en-kk\n  - lighteval|wmt19:en-lt\n  - lighteval|wmt19:en-ru\n  - lighteval|wmt19:en-zh\n  - lighteval|wmt19:fi-en\n  - lighteval|wmt19:fr-de\n  - lighteval|wmt19:gu-en\n  - lighteval|wmt19:kk-en\n  - lighteval|wmt19:lt-en\n  - lighteval|wmt19:ru-en\n  - lighteval|wmt19:zh-en\n  - lighteval|wmt20:cs-en\n  - lighteval|wmt20:de-en\n  - lighteval|wmt20:de-fr\n  - lighteval|wmt20:en-cs\n  - lighteval|wmt20:en-de\n  - lighteval|wmt20:en-iu\n  - lighteval|wmt20:en-ja\n  - lighteval|wmt20:en-km\n  - lighteval|wmt20:en-pl\n  - lighteval|wmt20:en-ps\n  - lighteval|wmt20:en-ru\n  - lighteval|wmt20:en-ta\n  - lighteval|wmt20:en-zh\n  - lighteval|wmt20:fr-de\n  - lighteval|wmt20:iu-en\n  - lighteval|wmt20:ja-en\n  - lighteval|wmt20:km-en\n  - lighteval|wmt20:pl-en\n  - lighteval|wmt20:ps-en\n  - lighteval|wmt20:ru-en\n  - lighteval|wmt20:ta-en\n  - lighteval|wmt20:zh-en\n  - lighteval|wsc273\n  - lighteval|xcopa:en\n  - lighteval|xcopa:et\n  - lighteval|xcopa:ht\n  - lighteval|xcopa:id\n  - lighteval|xcopa:it\n  - lighteval|xcopa:qu\n  - lighteval|xcopa:sw\n  - lighteval|xcopa:ta\n  - lighteval|xcopa:th\n  - lighteval|xcopa:tr\n  - lighteval|xcopa:vi\n  - lighteval|xcopa:zh\n  - lighteval|xstory_cloze:ar\n  - lighteval|xstory_cloze:en\n  - lighteval|xstory_cloze:es\n  - lighteval|xstory_cloze:eu\n  - lighteval|xstory_cloze:hi\n  - lighteval|xstory_cloze:id\n  - lighteval|xstory_cloze:my\n  - lighteval|xstory_cloze:ru\n  - lighteval|xstory_cloze:sw\n  - lighteval|xstory_cloze:te\n  - lighteval|xstory_cloze:zh\n  - lighteval|xwinograd:en\n  - lighteval|xwinograd:fr\n  - lighteval|xwinograd:jp\n  - lighteval|xwinograd:pt\n  - lighteval|xwinograd:ru\n  - lighteval|xwinograd:zh\n\n- original:\n  - original|arc:c:letters\n  - original|arc:c:options\n  - original|arc:c:simple\n  - original|mmlu:abstract_algebra\n  - original|mmlu:anatomy\n  - original|mmlu:astronomy\n  - original|mmlu:business_ethics\n  - original|mmlu:clinical_knowledge\n  - original|mmlu:college_biology\n  - original|mmlu:college_chemistry\n  - original|mmlu:college_computer_science\n  - original|mmlu:college_mathematics\n  - original|mmlu:college_medicine\n  - original|mmlu:college_physics\n  - original|mmlu:computer_security\n  - original|mmlu:conceptual_physics\n  - original|mmlu:econometrics\n  - original|mmlu:electrical_engineering\n  - original|mmlu:elementary_mathematics\n  - original|mmlu:formal_logic\n  - original|mmlu:global_facts\n  - original|mmlu:high_school_biology\n  - original|mmlu:high_school_chemistry\n  - original|mmlu:high_school_computer_science\n  - original|mmlu:high_school_european_history\n  - original|mmlu:high_school_geography\n  - original|mmlu:high_school_government_and_politics\n  - original|mmlu:high_school_macroeconomics\n  - original|mmlu:high_school_mathematics\n  - original|mmlu:high_school_microeconomics\n  - original|mmlu:high_school_physics\n  - original|mmlu:high_school_psychology\n  - original|mmlu:high_school_statistics\n  - original|mmlu:high_school_us_history\n  - original|mmlu:high_school_world_history\n  - original|mmlu:human_aging\n  - original|mmlu:human_sexuality\n  - original|mmlu:international_law\n  - original|mmlu:jurisprudence\n  - original|mmlu:logical_fallacies\n  - original|mmlu:machine_learning\n  - original|mmlu:management\n  - original|mmlu:marketing\n  - original|mmlu:medical_genetics\n  - original|mmlu:miscellaneous\n  - original|mmlu:moral_disputes\n  - original|mmlu:moral_scenarios\n  - original|mmlu:nutrition\n  - original|mmlu:philosophy\n  - original|mmlu:prehistory\n  - original|mmlu:professional_accounting\n  - original|mmlu:professional_law\n  - original|mmlu:professional_medicine\n  - original|mmlu:professional_psychology\n  - original|mmlu:public_relations\n  - original|mmlu:security_studies\n  - original|mmlu:sociology\n  - original|mmlu:us_foreign_policy\n  - original|mmlu:virology\n  - original|mmlu:world_religions\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Eval on std benchmarks\n!lighteval accelerate \\\n    \"pretrained=Qwen/Qwen2.5-0.5B-Instruct\" \\\n    \"helm|mmlu:formal_logic|0|0,helm|boolq|0|0,helm|openbookqa|0|0,lighteval|coqa|0|0,leaderboard|truthfulqa:mc|0|0,lighteval|toxigen|0|0\" \\\n    --use-chat-template \\\n    --max-samples 50 \\\n    --override-batch-size 256 \\\n    --output-dir \"./results\" \\\n    --save-details","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yNtQrN3mJHBp","outputId":"dafa75b5-8e07-47ae-bea4-6d1198314e12","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:14:46.465731Z","iopub.execute_input":"2025-03-30T06:14:46.465969Z","iopub.status.idle":"2025-03-30T06:15:16.279227Z","shell.execute_reply.started":"2025-03-30T06:14:46.465947Z","shell.execute_reply":"2025-03-30T06:15:16.278359Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"[2025-03-30 06:14:48,781] [\u001b[32m    INFO\u001b[0m]: NumExpr defaulting to 4 threads. (utils.py:162)\u001b[0m\n[2025-03-30 06:14:49,092] [\u001b[32m    INFO\u001b[0m]: PyTorch version 2.5.1+cu121 available. (config.py:54)\u001b[0m\n[2025-03-30 06:14:49,093] [\u001b[32m    INFO\u001b[0m]: Polars version 1.9.0 available. (config.py:66)\u001b[0m\n[2025-03-30 06:14:49,094] [\u001b[32m    INFO\u001b[0m]: Duckdb version 1.1.3 available. (config.py:77)\u001b[0m\n[2025-03-30 06:14:49,095] [\u001b[32m    INFO\u001b[0m]: TensorFlow version 2.17.1 available. (config.py:112)\u001b[0m\n[2025-03-30 06:14:49,096] [\u001b[32m    INFO\u001b[0m]: JAX version 0.4.33 available. (config.py:125)\u001b[0m\n2025-03-30 06:14:49.664919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-30 06:14:49.687002: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-30 06:14:49.693320: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[2025-03-30 06:14:56,325] [\u001b[33m WARNING\u001b[0m]: --max_samples WAS SET. THESE NUMBERS ARE ONLY PARTIAL AND SHOULD NOT BE USED FOR COMPARISON UNLESS YOU KNOW WHAT YOU ARE DOING. (pipeline.py:149)\u001b[0m\n[2025-03-30 06:14:56,327] [\u001b[32m    INFO\u001b[0m]: Test gather tensor (parallelism.py:133)\u001b[0m\n[2025-03-30 06:14:56,466] [\u001b[32m    INFO\u001b[0m]: gathered_tensor tensor([0], device='cuda:0'), should be [0] (parallelism.py:136)\u001b[0m\n[2025-03-30 06:14:56,467] [\u001b[32m    INFO\u001b[0m]: --- LOADING MODEL --- (pipeline.py:188)\u001b[0m\n[2025-03-30 06:14:56,891] [\u001b[32m    INFO\u001b[0m]: Tokenizer truncation and padding size set to the left side. (transformers_model.py:539)\u001b[0m\n[2025-03-30 06:14:56,998] [\u001b[32m    INFO\u001b[0m]: Setting model parallel to True since the number of local processes is 1 and the number of GPUs is 2 (transformers_model.py:402)\u001b[0m\n[2025-03-30 06:14:56,999] [\u001b[32m    INFO\u001b[0m]: Model parallel was set to True, setting max memory per GPU to {0: 15208677376, 1: 15407906816} and device map to auto (transformers_model.py:417)\u001b[0m\ngeneration_config.json: 100%|██████████████████| 242/242 [00:00<00:00, 1.54MB/s]\n[2025-03-30 06:14:58,100] [\u001b[32m    INFO\u001b[0m]: --- LOADING TASKS --- (pipeline.py:215)\u001b[0m\n[2025-03-30 06:14:58,100] [\u001b[32m    INFO\u001b[0m]: Found 1 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/ifeval/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:58,100] [\u001b[32m    INFO\u001b[0m]: Found 6 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/tiny_benchmarks/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:58,100] [\u001b[32m    INFO\u001b[0m]: Found 1 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/mt_bench/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:58,100] [\u001b[32m    INFO\u001b[0m]: Found 4 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/mix_eval/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:58,100] [\u001b[32m    INFO\u001b[0m]: Found 5 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/olympiade_bench/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:58,100] [\u001b[32m    INFO\u001b[0m]: Found 1 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/hle/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:58,101] [\u001b[32m    INFO\u001b[0m]: Found 21 custom tasks in /usr/local/lib/python3.10/dist-packages/lighteval/tasks/extended/lcb/main.py (registry.py:141)\u001b[0m\n[2025-03-30 06:14:58,104] [\u001b[32m    INFO\u001b[0m]: lighteval/boolq_helm default (lighteval_task.py:187)\u001b[0m\n[2025-03-30 06:14:58,105] [\u001b[32m    INFO\u001b[0m]: lighteval/boolq_helm default (lighteval_task.py:187)\u001b[0m\n[2025-03-30 06:14:58,105] [\u001b[33m WARNING\u001b[0m]: Careful, the task helm|boolq:contrastset is using evaluation data to build the few shot examples. (lighteval_task.py:260)\u001b[0m\n[2025-03-30 06:14:58,105] [\u001b[32m    INFO\u001b[0m]: lighteval/mmlu formal_logic (lighteval_task.py:187)\u001b[0m\n[2025-03-30 06:14:58,105] [\u001b[32m    INFO\u001b[0m]: openbookqa main (lighteval_task.py:187)\u001b[0m\n[2025-03-30 06:14:58,105] [\u001b[32m    INFO\u001b[0m]: truthful_qa multiple_choice (lighteval_task.py:187)\u001b[0m\n[2025-03-30 06:14:58,105] [\u001b[33m WARNING\u001b[0m]: Careful, the task leaderboard|truthfulqa:mc is using evaluation data to build the few shot examples. (lighteval_task.py:260)\u001b[0m\n[2025-03-30 06:14:58,105] [\u001b[32m    INFO\u001b[0m]: coqa default (lighteval_task.py:187)\u001b[0m\n[2025-03-30 06:14:58,105] [\u001b[32m    INFO\u001b[0m]: skg/toxigen-data annotated (lighteval_task.py:187)\u001b[0m\nboolq_helm.py: 100%|███████████████████████| 1.93k/1.93k [00:00<00:00, 15.8MB/s]\n0000.parquet: 100%|████████████████████████| 3.70M/3.70M [00:00<00:00, 48.8MB/s]\n0000.parquet: 100%|█████████████████████████| 1.30M/1.30M [00:00<00:00, 138MB/s]\nGenerating train split: 100%|████| 9427/9427 [00:00<00:00, 150100.23 examples/s]\nGenerating validation split: 100%|█| 3270/3270 [00:00<00:00, 301013.39 examples/\nREADME.md: 100%|███████████████████████████| 39.7k/39.7k [00:00<00:00, 18.9MB/s]\nmmlu.py: 100%|█████████████████████████████| 5.76k/5.76k [00:00<00:00, 36.1MB/s]\n0000.parquet: 100%|█████████████████████████| 47.5M/47.5M [00:00<00:00, 166MB/s]\n0000.parquet: 100%|████████████████████████| 21.5k/21.5k [00:00<00:00, 73.0MB/s]\n0000.parquet: 100%|████████████████████████| 6.56k/6.56k [00:00<00:00, 33.8MB/s]\n0000.parquet: 100%|████████████████████████| 4.81k/4.81k [00:00<00:00, 25.2MB/s]\nGenerating auxiliary_train split: 100%|█| 99842/99842 [00:00<00:00, 249867.66 ex\nGenerating test split: 100%|████████| 126/126 [00:00<00:00, 51303.98 examples/s]\nGenerating validation split: 100%|█████| 14/14 [00:00<00:00, 6377.78 examples/s]\nGenerating dev split: 100%|██████████████| 5/5 [00:00<00:00, 2721.10 examples/s]\nREADME.md: 100%|███████████████████████████| 9.06k/9.06k [00:00<00:00, 45.4MB/s]\n\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/lighteval/\u001b[0m\u001b[1;33mmain_accelerate.py\u001b[0m:\u001b[94m198\u001b[0m in \u001b[92maccelerate\u001b[0m           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args_dict[\u001b[33m\"\u001b[0m\u001b[33mcompile\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[96mbool\u001b[0m(model_args_dict[\u001b[33m\"\u001b[0m\u001b[33mcompile\u001b[0m\u001b[33m\"\u001b[0m]) \u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mcompile\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m mo   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_config = TransformersModelConfig(**model_args_dict)                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m198 \u001b[2m│   \u001b[0mpipeline = Pipeline(                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   \u001b[0mtasks=tasks,                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   │   \u001b[0mpipeline_parameters=pipeline_params,                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mevaluation_tracker=evaluation_tracker,                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/lighteval/\u001b[0m\u001b[1;33mpipeline.py\u001b[0m:\u001b[94m162\u001b[0m in \u001b[92m__init__\u001b[0m                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   \u001b[0mgeneration_parameters = asdict(model_config.generation_parameters) \u001b[94mif\u001b[0m model_conf   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.evaluation_tracker.general_config_logger.log_model_info(generation_paramete   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m162 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._init_tasks_and_requests(tasks=tasks)                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._init_random_seeds()                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Final results\u001b[0m                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.final_dict: \u001b[96mdict\u001b[0m = \u001b[94mNone\u001b[0m                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/lighteval/\u001b[0m\u001b[1;33mpipeline.py\u001b[0m:\u001b[94m226\u001b[0m in \u001b[92m_init_tasks_and_requests\u001b[0m    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m223 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# review if they have to be updated.\u001b[0m                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m224 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._metric_options:                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._update_num_samples(task_dict)                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m226 \u001b[2m│   │   │   \u001b[0mLightevalTask.load_datasets(\u001b[96mlist\u001b[0m(task_dict.values()), \u001b[96mself\u001b[0m.pipeline_paramete   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m228 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.evaluation_tracker.task_config_logger.log(task_dict)                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m229 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/lighteval/tasks/\u001b[0m\u001b[1;33mlighteval_task.py\u001b[0m:\u001b[94m546\u001b[0m in \u001b[92mload_datasets\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m543 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m544 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m545 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dataset_loading_processes <= \u001b[94m1\u001b[0m:                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m546 \u001b[2m│   │   │   \u001b[0mdatasets = [                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m547 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdownload_dataset_worker(                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m548 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mtask.dataset_path,                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m549 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mtask.dataset_config_name,                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/lighteval/tasks/\u001b[0m\u001b[1;33mlighteval_task.py\u001b[0m:\u001b[94m547\u001b[0m in \u001b[92m<listcomp>\u001b[0m      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m544 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m545 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dataset_loading_processes <= \u001b[94m1\u001b[0m:                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m546 \u001b[0m\u001b[2m│   │   │   \u001b[0mdatasets = [                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m547 \u001b[2m│   │   │   │   \u001b[0mdownload_dataset_worker(                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m548 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mtask.dataset_path,                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m549 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mtask.dataset_config_name,                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m550 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mtask.trust_dataset,                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/lighteval/utils/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m228\u001b[0m in \u001b[92mdownload_dataset_worker\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mWorker function to download a dataset from the HuggingFace Hub.\u001b[0m                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mUsed for parallel dataset loading.\u001b[0m                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m228 \u001b[2m│   \u001b[0mdataset = load_dataset(                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m229 \u001b[0m\u001b[2m│   │   \u001b[0mpath=dataset_path,                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m230 \u001b[0m\u001b[2m│   │   \u001b[0mname=dataset_config_name,                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m231 \u001b[0m\u001b[2m│   │   \u001b[0mdata_dir=\u001b[94mNone\u001b[0m,                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/\u001b[0m\u001b[1;33mload.py\u001b[0m:\u001b[94m2129\u001b[0m in \u001b[92mload_dataset\u001b[0m                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2126 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2127 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2128 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Create a dataset builder\u001b[0m                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2129 \u001b[2m│   \u001b[0mbuilder_instance = load_dataset_builder(                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2130 \u001b[0m\u001b[2m│   │   \u001b[0mpath=path,                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2131 \u001b[0m\u001b[2m│   │   \u001b[0mname=name,                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2132 \u001b[0m\u001b[2m│   │   \u001b[0mdata_dir=data_dir,                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/\u001b[0m\u001b[1;33mload.py\u001b[0m:\u001b[94m1849\u001b[0m in \u001b[92mload_dataset_builder\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1846 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m storage_options \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1847 \u001b[0m\u001b[2m│   │   \u001b[0mdownload_config = download_config.copy() \u001b[94mif\u001b[0m download_config \u001b[94melse\u001b[0m DownloadConfig(  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1848 \u001b[0m\u001b[2m│   │   \u001b[0mdownload_config.storage_options.update(storage_options)                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1849 \u001b[2m│   \u001b[0mdataset_module = dataset_module_factory(                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1850 \u001b[0m\u001b[2m│   │   \u001b[0mpath,                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1851 \u001b[0m\u001b[2m│   │   \u001b[0mrevision=revision,                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1852 \u001b[0m\u001b[2m│   │   \u001b[0mdownload_config=download_config,                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/\u001b[0m\u001b[1;33mload.py\u001b[0m:\u001b[94m1731\u001b[0m in \u001b[92mdataset_module_factory\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1728 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCouldn\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt find any data file at \u001b[0m\u001b[33m{\u001b[0mrelative_to_absolute_path(  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1729 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCouldn\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt find \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpath\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m on the Hugging Face Hub either: \u001b[0m\u001b[33m{\u001b[0m\u001b[96mty\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1730 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m) \u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[94mNone\u001b[0m                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1731 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m e1 \u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[94mNone\u001b[0m                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1732 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m trust_remote_code:                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mFileNotFoundError\u001b[0m(                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCouldn\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt find a dataset script at \u001b[0m\u001b[33m{\u001b[0mrelative_to_absolute_path(combined_path  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/\u001b[0m\u001b[1;33mload.py\u001b[0m:\u001b[94m1696\u001b[0m in \u001b[92mdataset_module_factory\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1693 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mdownload_config=download_config,                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1694 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mdownload_mode=download_mode,                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1695 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0muse_exported_dataset_infos=use_exported_dataset_infos,                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1696 \u001b[2m│   │   │   │   \u001b[0m).get_module()                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1697 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m GatedRepoError \u001b[94mas\u001b[0m e:                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1698 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmessage = \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mDataset \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpath\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m is a gated dataset on the Hub.\u001b[0m\u001b[33m\"\u001b[0m              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1699 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m e.response.status_code == \u001b[94m401\u001b[0m:                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/\u001b[0m\u001b[1;33mload.py\u001b[0m:\u001b[94m1026\u001b[0m in \u001b[92mget_module\u001b[0m                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1023 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m download_config.download_desc \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1024 \u001b[0m\u001b[2m│   │   │   \u001b[0mdownload_config.download_desc = \u001b[33m\"\u001b[0m\u001b[33mDownloading standalone yaml\u001b[0m\u001b[33m\"\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1025 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1026 \u001b[2m│   │   │   \u001b[0mstandalone_yaml_path = cached_path(                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1027 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhf_dataset_url(\u001b[96mself\u001b[0m.name, config.REPOYAML_FILENAME, revision=\u001b[96mself\u001b[0m.commit  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1028 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdownload_config=download_config,                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1029 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/utils/\u001b[0m\u001b[1;33mfile_utils.py\u001b[0m:\u001b[94m180\u001b[0m in \u001b[92mcached_path\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 177 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m url_or_filename.startswith(\u001b[33m\"\u001b[0m\u001b[33mhf://\u001b[0m\u001b[33m\"\u001b[0m):                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 178 \u001b[0m\u001b[2m│   │   │   \u001b[0mresolved_path = huggingface_hub.HfFileSystem(                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 179 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mendpoint=config.HF_ENDPOINT, token=download_config.token                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 180 \u001b[2m│   │   │   \u001b[0m).resolve_path(url_or_filename)                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 181 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 182 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput_path = huggingface_hub.HfApi(                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 183 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mendpoint=config.HF_ENDPOINT,                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhf_file_system.py\u001b[0m:\u001b[94m198\u001b[0m in \u001b[92mresolve_path\u001b[0m    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 195 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 196 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpath_in_repo = \u001b[33m\"\u001b[0m\u001b[33m\"\u001b[0m                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 197 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mrevision = _align_revision_in_path_with_revision(unquote(revision_in_pat  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 198 \u001b[2m│   │   │   │   \u001b[0mrepo_and_revision_exist, err = \u001b[96mself\u001b[0m._repo_and_revision_exist(repo_type,   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 199 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m repo_and_revision_exist:                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 200 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m_raise_file_not_found(path, err)                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 201 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhf_file_system.py\u001b[0m:\u001b[94m125\u001b[0m in                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92m_repo_and_revision_exist\u001b[0m                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 122 \u001b[0m\u001b[2m│   \u001b[0m) -> Tuple[\u001b[96mbool\u001b[0m, Optional[\u001b[96mException\u001b[0m]]:                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 123 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (repo_type, repo_id, revision) \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._repo_and_revision_exists_cache:    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 124 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 125 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._api.repo_info(                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 126 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mrepo_id, revision=revision, repo_type=repo_type, timeout=constants.H  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 127 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 128 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m (RepositoryNotFoundError, HFValidationError) \u001b[94mas\u001b[0m e:                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m114\u001b[0m in \u001b[92m_inner_fn\u001b[0m    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, has_token=ha   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhf_api.py\u001b[0m:\u001b[94m2734\u001b[0m in \u001b[92mrepo_info\u001b[0m              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2731 \u001b[0m\u001b[2m│   │   │   \u001b[0mmethod = \u001b[96mself\u001b[0m.space_info  \u001b[2m# type: ignore\u001b[0m                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2732 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2733 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mUnsupported repo type.\u001b[0m\u001b[33m\"\u001b[0m)                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2734 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m method(                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2735 \u001b[0m\u001b[2m│   │   │   \u001b[0mrepo_id,                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2736 \u001b[0m\u001b[2m│   │   │   \u001b[0mrevision=revision,                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2737 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken=token,                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m114\u001b[0m in \u001b[92m_inner_fn\u001b[0m    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, has_token=ha   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhf_api.py\u001b[0m:\u001b[94m2591\u001b[0m in \u001b[92mdataset_info\u001b[0m           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2588 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m expand:                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2589 \u001b[0m\u001b[2m│   │   │   \u001b[0mparams[\u001b[33m\"\u001b[0m\u001b[33mexpand\u001b[0m\u001b[33m\"\u001b[0m] = expand                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2590 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2591 \u001b[2m│   │   \u001b[0mr = get_session().get(path, headers=headers, timeout=timeout, params=params)      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2592 \u001b[0m\u001b[2m│   │   \u001b[0mhf_raise_for_status(r)                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2593 \u001b[0m\u001b[2m│   │   \u001b[0mdata = r.json()                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2594 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m DatasetInfo(**data)                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/requests/\u001b[0m\u001b[1;33msessions.py\u001b[0m:\u001b[94m602\u001b[0m in \u001b[92mget\u001b[0m                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m599 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m600 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m601 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs.setdefault(\u001b[33m\"\u001b[0m\u001b[33mallow_redirects\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mTrue\u001b[0m)                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m602 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.request(\u001b[33m\"\u001b[0m\u001b[33mGET\u001b[0m\u001b[33m\"\u001b[0m, url, **kwargs)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m603 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m604 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92moptions\u001b[0m(\u001b[96mself\u001b[0m, url, **kwargs):                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m605 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33mr\u001b[0m\u001b[33m\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\u001b[0m                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/requests/\u001b[0m\u001b[1;33msessions.py\u001b[0m:\u001b[94m589\u001b[0m in \u001b[92mrequest\u001b[0m                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m586 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mallow_redirects\u001b[0m\u001b[33m\"\u001b[0m: allow_redirects,                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m587 \u001b[0m\u001b[2m│   │   \u001b[0m}                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m588 \u001b[0m\u001b[2m│   │   \u001b[0msend_kwargs.update(settings)                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m589 \u001b[2m│   │   \u001b[0mresp = \u001b[96mself\u001b[0m.send(prep, **send_kwargs)                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m590 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m591 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m resp                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m592 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/requests/\u001b[0m\u001b[1;33msessions.py\u001b[0m:\u001b[94m703\u001b[0m in \u001b[92msend\u001b[0m                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m700 \u001b[0m\u001b[2m│   │   \u001b[0mstart = preferred_clock()                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m701 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m702 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Send the request\u001b[0m                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m703 \u001b[2m│   │   \u001b[0mr = adapter.send(request, **kwargs)                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m704 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m705 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Total elapsed time of the request (approximately)\u001b[0m                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m706 \u001b[0m\u001b[2m│   │   \u001b[0melapsed = preferred_clock() - start                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_http.py\u001b[0m:\u001b[94m96\u001b[0m in \u001b[92msend\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m constants.HF_DEBUG:                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogger.debug(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mSend: \u001b[0m\u001b[33m{\u001b[0m_curlify(request)\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 96 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().send(request, *args, **kwargs)                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m requests.RequestException \u001b[94mas\u001b[0m e:                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   │   \u001b[0mrequest_id = request.headers.get(X_AMZN_TRACE_ID)                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m request_id \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/requests/\u001b[0m\u001b[1;33madapters.py\u001b[0m:\u001b[94m713\u001b[0m in \u001b[92msend\u001b[0m                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m710 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# This branch is for urllib3 versions earlier than v1.22\u001b[0m                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m711 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m SSLError(e, request=request)                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m712 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(e, ReadTimeoutError):                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m713 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m ReadTimeout(e, request=request)                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m714 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(e, _InvalidHeader):                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m715 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m InvalidHeader(e, request=request)                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m716 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mReadTimeout: \u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mReadTimeoutError\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"HTTPSConnectionPool\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhost\u001b[0m\u001b[32m='huggingface.co', \u001b[0m\u001b[32mport\u001b[0m\u001b[32m=\u001b[0m\u001b[32m443\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: Read timed \u001b[0m\n\u001b[32mout. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mread \u001b[0m\u001b[32mtimeout\u001b[0m\u001b[32m=\u001b[0m\u001b[32m10\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32mRequest ID: 756eb62b-7e7f-4264-bffa-e3e7079386f1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Tuning base model","metadata":{"id":"DMbEJIQW3hWb"}},{"cell_type":"code","source":"# Load the dataset\ndataset = load_dataset(\"arcee-ai/EvolKit-20k\")\n\n# Examine dataset structure\nprint(dataset)\nprint(f\"Number of examples: {len(dataset['train'])}\")\n\n# Look at a few examples\nfor i in range(3):\n    convo = dataset['train'][i]['conversations']\n\n    instruction = next((turn['value'] for turn in convo if turn['from'] == 'human'), '')\n    output = next((turn['value'] for turn in convo if turn['from'] == 'gpt'), '')\n\n    # print(f\"\\nExample {i+1}:\")\n    # print(f\"Instruction: {instruction}\")\n    # print(f\"Output: {output}\")","metadata":{"id":"Lsph6Zzk2zYx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c3d2723-5cf1-4d2d-cccb-0fa5767690d2","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:15:16.281652Z","iopub.execute_input":"2025-03-30T06:15:16.281903Z","iopub.status.idle":"2025-03-30T06:15:23.113136Z","shell.execute_reply.started":"2025-03-30T06:15:16.281880Z","shell.execute_reply":"2025-03-30T06:15:23.112490Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/233 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6af6938f9f084ea3accd38b6624b6d64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tomb_evolved_20k.json:   0%|          | 0.00/85.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6fb3359bd304832974c9b16fe5953fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aea44cb330e846cfbfa467e17a5fd0c0"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['conversations'],\n        num_rows: 20000\n    })\n})\nNumber of examples: 20000\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Check max_seq_token\n\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nimport numpy as np\n\n# Load dataset\ndataset = load_dataset(\"arcee-ai/EvolKit-20k\")\ntrain_data = dataset[\"train\"]\n\n# Load Qwen2.5-0.5B tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\", trust_remote_code=True)\n\n# Convert conversasion to text\ndef format_conversation(example):\n    conv = example[\"conversations\"]\n    full_text = \"\"\n    for turn in conv:\n        role = turn[\"from\"]\n        value = turn[\"value\"]\n        if role == \"human\":\n            full_text += f\"<|user|>\\n{value}\\n\"\n        elif role == \"gpt\":\n            full_text += f\"<|assistant|>\\n{value}\\n\"\n    return {\"text\": full_text.strip()}\n\n# Format train set\nformatted_dataset = train_data.map(format_conversation)\n\n# Calc token_len\ndef get_token_length(example):\n    return {\"length\": len(tokenizer(example[\"text\"])[\"input_ids\"])}\n\nlength_dataset = formatted_dataset.map(get_token_length)\n\n# Statistic len\nlengths = length_dataset[\"length\"]\nprint(f\"Max sequence length: {max(lengths)} tokens\")\n\npercentiles = np.percentile(lengths, [90, 95, 99])\nprint(f\"90% sample < {int(percentiles[0])} tokens\")\nprint(f\"95% sample < {int(percentiles[1])} tokens\")\nprint(f\"99% sample < {int(percentiles[2])} tokens\")","metadata":{"id":"AlYrwDORXTam","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:15:23.114271Z","iopub.execute_input":"2025-03-30T06:15:23.114511Z","iopub.status.idle":"2025-03-30T06:16:17.420951Z","shell.execute_reply.started":"2025-03-30T06:15:23.114489Z","shell.execute_reply":"2025-03-30T06:16:17.420264Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61bebb63347c47eba30eca18ef9c1346"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"600fa6d55079420694f89ab6cf837e28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f305a848c42c4d99a4c3067d0aad2114"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d57033116d1b458d90740056671c7c2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"928a9fda2d10459b8895ebb209f3848f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d7aeb55e0f54949b0c6b1873dc6104e"}},"metadata":{}},{"name":"stdout","text":"Max sequence length: 4434 tokens\n90% sample < 1198 tokens\n95% sample < 1299 tokens\n99% sample < 1560 tokens\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def format_dataset(example):\n    \"\"\"\n    Format dataset examples as messages suitable for chat-based fine-tuning.\n    \"\"\"\n    conversation = example[\"conversations\"]\n    instruction = next((msg[\"value\"] for msg in conversation if msg[\"from\"] == \"human\"), \"\")\n    output = next((msg[\"value\"] for msg in conversation if msg[\"from\"] == \"gpt\"), \"\")\n\n    messages = [\n        {\"role\": \"user\", \"content\": instruction}\n    ]\n    if output:\n        messages.append({\"role\": \"assistant\", \"content\": output})\n\n    return {\"messages\": messages}\n\n# Apply formatting to the dataset\nformatted_dataset = dataset.map(format_dataset, remove_columns=dataset[\"train\"].column_names)\n\n# Split dataset to include a validation set\nsplit_dataset = formatted_dataset[\"train\"].train_test_split(test_size=0.05, seed=42)\ntrain_dataset = split_dataset[\"train\"]\nval_dataset = split_dataset[\"test\"]\n\nprint(f\"Training examples: {len(train_dataset)}\")\nprint(f\"Validation examples: {len(val_dataset)}\")\n","metadata":{"id":"jl-1XpTXf9WM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb17c810-989a-4708-e7a5-a5df814d92c3","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:16:17.421944Z","iopub.execute_input":"2025-03-30T06:16:17.422291Z","iopub.status.idle":"2025-03-30T06:16:18.973077Z","shell.execute_reply.started":"2025-03-30T06:16:17.422256Z","shell.execute_reply":"2025-03-30T06:16:18.972202Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"319de12cb3b1420aa60a157b9b912fea"}},"metadata":{}},{"name":"stdout","text":"Training examples: 19000\nValidation examples: 1000\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Model ID for the base version\nbase_model_id = \"Qwen/Qwen2.5-0.5B\"\n\n# Load tokenizer\nbase_tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n\n# Ensure the tokenizer has chat template and special tokens\nif base_tokenizer.chat_template is None:\n    # If no chat template, use the one from the instruct model\n    base_tokenizer = AutoTokenizer.from_pretrained(instruct_model_id)\n\n# Add padding token if it doesn't exist\nif base_tokenizer.pad_token is None:\n    base_tokenizer.pad_token = base_tokenizer.eos_token\n\n# Configure model loading with 4-bit quantization\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load the base model\nbase_model = AutoModelForCausalLM.from_pretrained(\n    base_model_id,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sywcuuqlLdEx","outputId":"fdf835f9-8b70-480c-f287-8c983dce829b","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:16:18.974022Z","iopub.execute_input":"2025-03-30T06:16:18.974354Z","iopub.status.idle":"2025-03-30T06:16:24.778436Z","shell.execute_reply.started":"2025-03-30T06:16:18.974323Z","shell.execute_reply":"2025-03-30T06:16:24.777806Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"020767f8527c4167b4d4ae1733bc45b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c35445fd1dd34891b69fbed74523ac51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c5042775352401a9f1c209d270d8f3a"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"base_model.gradient_checkpointing_enable()\nbase_model.enable_input_require_grads()","metadata":{"id":"9yCd_VEoW8ZO","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:16:24.779207Z","iopub.execute_input":"2025-03-30T06:16:24.779417Z","iopub.status.idle":"2025-03-30T06:16:24.783876Z","shell.execute_reply.started":"2025-03-30T06:16:24.779398Z","shell.execute_reply":"2025-03-30T06:16:24.783163Z"},"scrolled":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Define LoRA configuration\nlora_config = LoraConfig(\n    r=16,                     # Rank dimension (balance between capacity and memory)\n    lora_alpha=32,            # LoRA scaling factor (typically 2x rank)\n    lora_dropout=0.05,        # Dropout probability for regularization\n    bias=\"none\",              # Do not train bias terms\n    task_type=\"CAUSAL_LM\",    # Task type for causal language modeling\n    target_modules=[\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # Attention modules\n        \"gate_proj\", \"up_proj\", \"down_proj\"     # MLP modules\n    ],\n)\n\n# Set up training arguments\ntraining_args = SFTConfig(\n    num_train_epochs=3,                 # Number of training epochs\n    output_dir=\"./qwen2.5-0.5B-finetuned-evolkit\",\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=8,      # Effective batch size = 4 * 4 = 16\n    per_device_eval_batch_size=1,\n    optim=\"paged_adamw_32bit\",          # Memory-efficient optimizer\n    learning_rate=2e-4,                 # Learning rate\n    lr_scheduler_type=\"cosine\",         # Learning rate schedule\n    max_seq_length=1536,                # 1536\n    warmup_ratio=0.05,                  # Warmup period\n    logging_steps=10,                   # Log every 10 steps\n    eval_steps=200,                     # Evaluate every 100 steps\n    save_steps=200,                     # Save checkpoint every 200 steps\n    max_grad_norm=0.3,                  # Gradient clipping\n    # eval_strategy=\"epoch\",\n    eval_strategy=\"steps\",\n    fp16=True,                          # Use mixed precision training\n    packing=True,                       # Pack multiple sequences to maximize throughput\n    report_to=[\"tensorboard\"],\n)","metadata":{"id":"dwFwlcxCgD77","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:16:24.784537Z","iopub.execute_input":"2025-03-30T06:16:24.784799Z","iopub.status.idle":"2025-03-30T06:16:24.823748Z","shell.execute_reply.started":"2025-03-30T06:16:24.784768Z","shell.execute_reply":"2025-03-30T06:16:24.823161Z"},"scrolled":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Set up the trainer\ntrainer = SFTTrainer(\n    model=base_model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    peft_config=lora_config,\n\n)\ntrainer.tokenizer = base_tokenizer\n\n# Start training\ntrainer.train()\n\n# Save the trained adapter\ntrainer.save_model(\"./qwen2.5-0.5B-finetuned-evolkit\")","metadata":{"id":"j6oIA3cUgGgy","colab":{"base_uri":"https://localhost:8080/","height":195,"referenced_widgets":["fa722f3c0ec0418f9d61e9619ab92d52","7221e239c655427dab04669871eb938a","06f678cd16914a75a0e8ad904c7240af","0c3e1bd0cded45f99e34ee7f6810ac19","eeb700948afc47a0bc63a349e85ababe","6a476ffec28b4c56984c792c597e4c8a","146b9a1f89034bc7b9ff1013811b42e4","69e0adfd75f5498f874fdd055c41af7e","d2bf0454c45246f4a41c33c417aa22f1","cf50d895e3e44609a7b12f01c5054161","c162a9fb11d342628a3412a650aed318","fdf4f6c8ea504871aa0f2f88066800b1","87320e00eed84793bd6c450923483747","cebc701042834e58806924526425f76d","4b64521b164f4ba9b3433b6a1ddbc658","0d29c08d26164386a7b76c6f0267ff85","fefcf2e136d3459a891ad9040d1c6b1e","48e89d1f6b8a42ae860eaff6d78e0fe4","a842ba83af0044119059283df2beb85b","dfcd8787a1cc4538bbc163e3346c298f","66a28d6011cd4859a22e9359d293efb9","160ab91e81af43f7b59f4ab764ce5e91"]},"outputId":"18874c83-d82b-4a9f-8412-af8bfee26df1","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T06:16:24.824325Z","iopub.execute_input":"2025-03-30T06:16:24.824518Z","execution_failed":"2025-03-30T12:31:21.001Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/19000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98983ce538244031bdf1752f17829311"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/19000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"147fd654cd0e43a58a161aa279ca8411"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/19000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"934ed1b3d24f48b79c3cb69f7d79277a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Packing train dataset:   0%|          | 0/19000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad77602505564a56aea6cfddc583475a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Converting eval dataset to ChatML:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b78e826eb22d43fbbd87ee0b5c4126ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ad50dded81940d9abe3f9838f1e5135"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db683ba4cb9847f187b5a8065827161f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Packing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"118ba35dcdc84e8d9a293438a812a8e5"}},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use `Trainer.processing_class = processing_class` instead.\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1484' max='2175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1484/2175 5:33:59 < 2:35:43, 0.07 it/s, Epoch 2.04/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>10.515600</td>\n      <td>1.315663</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>10.302600</td>\n      <td>1.288263</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>10.308500</td>\n      <td>1.274458</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>9.702100</td>\n      <td>1.267175</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>9.754300</td>\n      <td>1.261425</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>9.698500</td>\n      <td>1.255899</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>9.570100</td>\n      <td>1.251262</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"from peft import PeftModel\n\n# Load the base model in full precision\nbase_model_fp16 = AutoModelForCausalLM.from_pretrained(\n    base_model_id,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\n# Load the PEFT adapter\nadapter_model = PeftModel.from_pretrained(base_model_fp16, \"./qwen2.5-0.5B-finetuned-evolkit\")\n\n# Merge weights\nmerged_model = adapter_model.merge_and_unload()\n\n# Save the merged model\nmerged_model.save_pretrained(\"./qwen2.5-0.5B-finetuned-evolkit-merged\")\nbase_tokenizer.save_pretrained(\"./qwen2.5-0.5B-finetuned-evolkit-merged\")","metadata":{"id":"xCzn1dBUgIS0","scrolled":true,"trusted":true,"execution":{"execution_failed":"2025-03-30T12:31:21.003Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tuning on my own dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM\nfrom trl import SFTTrainer, SFTConfig\nfrom peft import LoraConfig\nimport numpy as np\nimport torch\n\n# ======= LOAD DATASET =======\ndataset = load_dataset(\"phatvucoder/perfume-assistant\")\nprint(dataset)\nprint(f\"Number of examples: {len(dataset['train'])}\")\nprint(\"Example:\", dataset['train'][0])\n\n# ======= LOAD TOKENIZER =======\nmodel_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n\n# ======= FORMAT USING CHAT TEMPLATE =======\ndef format_conversation(example):\n    formatted_text = tokenizer.apply_chat_template(\n        example[\"messages\"],\n        tokenize=False,\n        add_generation_prompt=False\n    )\n    return {\"text\": formatted_text}\n\ntrain_data = dataset[\"train\"].map(\n    format_conversation,\n    remove_columns=dataset[\"train\"].column_names\n)\nval_data = dataset[\"validation\"].map(\n    format_conversation,\n    remove_columns=dataset[\"validation\"].column_names\n)\n\n# ======= CHECK LENGTHS =======\ndef get_token_length(example):\n    return {\"length\": len(tokenizer(example[\"text\"])[\"input_ids\"])}\n    \ntoken_lengths = train_data.map(\n    get_token_length,\n    remove_columns=train_data.column_names\n)[\"length\"]\n\nprint(f\"\\n📏 Max token length: {max(token_lengths)}\")\nprint(\"📊 90%:\", int(np.percentile(token_lengths, 90)))\nprint(\"📊 95%:\", int(np.percentile(token_lengths, 95)))\nprint(\"📊 99%:\", int(np.percentile(token_lengths, 99)))\n\n# ======= FIX SPECIAL TOKENS =======\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# ======= LOAD MODEL W/ QUANTIZATION =======\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\nmodel.config.use_cache = False\n\nmodel.gradient_checkpointing_enable()\nmodel.enable_input_require_grads()\n\n# ======= LORA CONFIG =======\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n)\n\n# ======= TRAINING CONFIG =======\ntraining_args = SFTConfig(\n    output_dir=\"./qwen2.5-1.5B-Instruct-finetuned-perfume\",\n    num_train_epochs=4,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=1,\n    learning_rate=2e-4,\n    lr_scheduler_type=\"cosine\",\n    warmup_ratio=0.05,\n    max_seq_length=768,\n    logging_steps=10,\n    save_steps=20,\n    eval_steps=20,\n    max_grad_norm=0.5,\n    fp16=True,\n    packing=True,\n    report_to=[\"tensorboard\"],\n    eval_strategy=\"steps\",  # Hoặc \"epochs\"\n)\n\n# ======= START TRAINING =======\ntrainer = SFTTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=val_data,\n    peft_config=lora_config,\n)\ntrainer.processing_class = tokenizer\n\ntrainer.train()\n\n# ======= SAVE LORA ADAPTER =======\ntrainer.save_model(\"./qwen2.5-1.5B-Instruct-finetuned-perfume\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T02:28:46.305876Z","iopub.execute_input":"2025-03-31T02:28:46.306245Z","iopub.status.idle":"2025-03-31T03:19:05.963489Z","shell.execute_reply.started":"2025-03-31T02:28:46.306222Z","shell.execute_reply":"2025-03-31T03:19:05.962698Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/531 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eacc679552f54f0fb2e85f12ab1eb019"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/896k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fafd5350c1574a6cb34e72d1cabcc341"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/170k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5084dd31a345489ea9e4f5ba221a071a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2810 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09c4e7cace8d470dac13331ecf8f1ff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/503 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfb8eb75cc8446e1a6014ff6d759e2e0"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['messages'],\n        num_rows: 2810\n    })\n    validation: Dataset({\n        features: ['messages'],\n        num_rows: 503\n    })\n})\nNumber of examples: 2810\nExample: {'messages': [{'content': 'Bạn là một chuyên viên tư vấn nước hoa và chăm sóc khách hàng cho shop.', 'role': 'system'}, {'content': 'EDT có phù hợp để đi tiệc tối không?', 'role': 'user'}, {'content': 'EDT (Eau de Toilette) hoàn toàn có thể phù hợp đi tiệc tối, đặc biệt là những loại EDT có nhóm hương ấm áp hơn (như Oriental nhẹ, Woody) hoặc những bữa tiệc không quá trang trọng. Tuy nhiên, do độ lưu hương và tỏa hương thường không bằng EDP, bạn có thể cần xịt lại sau vài tiếng để duy trì mùi hương. Nếu muốn một mùi hương nổi bật và bền bỉ hơn cho tiệc tối, EDP thường là lựa chọn được ưu tiên hơn.', 'role': 'assistant'}]}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa362d146ece44d49ed08f4c060db013"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be42d0c83224487b97715d60edec78fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e99fc50b74ad40d59131579da5d300f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c5c7010cfab4b07a19c4fa15aa4da72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2810 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"860289876a28424a8d44035e84c83c9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/503 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72995860bcbc44b4a880ccbd76c48c9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2810 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1960d90b463c4ffaab0cb45ac3ae0d33"}},"metadata":{}},{"name":"stdout","text":"\n📏 Max token length: 892\n📊 90%: 323\n📊 95%: 434\n📊 99%: 619\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6430262e24c491bab97941af66f7c59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e7bf36a46f742c0813e080e5e6827f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1f151f4ecb043e19aec811b946705fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/2810 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2219876c037c47bbb15459034a87c3b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/2810 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"039eb8b1bb4140c2a8f3c27a8381d4b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/2810 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6051b20996ce40a58736b9c88502ea03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Packing train dataset:   0%|          | 0/2810 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"460febd6f8d643fa93cb04935c4b3997"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Converting eval dataset to ChatML:   0%|          | 0/503 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"183509201e5e45cbaef6f509d7ceae4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset:   0%|          | 0/503 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48d344842a114295a16ababd1ad37548"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/503 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0ae9b152d6d42949750816e1d570bda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Packing eval dataset:   0%|          | 0/503 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b80359f582d949b49c5aeb1852b6d1c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [180/180 49:31, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>7.102500</td>\n      <td>1.665940</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>6.069800</td>\n      <td>1.457833</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>5.255600</td>\n      <td>1.373847</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>5.123800</td>\n      <td>1.329985</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>4.829900</td>\n      <td>1.310826</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>4.510400</td>\n      <td>1.295062</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>4.529200</td>\n      <td>1.289866</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>4.275700</td>\n      <td>1.290403</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>4.321100</td>\n      <td>1.289637</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"!cp -r ./qwen2.5-1.5B-Instruct-finetuned-perfume/checkpoint-140 ./perfume-best-lora","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T03:24:23.113694Z","iopub.execute_input":"2025-03-31T03:24:23.114114Z","iopub.status.idle":"2025-03-31T03:24:23.530931Z","shell.execute_reply.started":"2025-03-31T03:24:23.114085Z","shell.execute_reply":"2025-03-31T03:24:23.529960Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\nfrom peft import PeftModel\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    \"Qwen/Qwen2.5-1.5B-Instruct\",\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\nmerged_model = PeftModel.from_pretrained(base_model, \"./perfume-best-lora\")\nmerged_model = merged_model.merge_and_unload()\nmerged_model.save_pretrained(\"./Qwen2.5-1.5B-Instruct-Perfumassist\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T03:27:25.414408Z","iopub.execute_input":"2025-03-31T03:27:25.414757Z","iopub.status.idle":"2025-03-31T03:27:49.904551Z","shell.execute_reply.started":"2025-03-31T03:27:25.414733Z","shell.execute_reply":"2025-03-31T03:27:49.903821Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\", trust_remote_code=True)\ntokenizer.save_pretrained(\"./Qwen2.5-1.5B-Instruct-Perfumassist\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T04:00:37.990231Z","iopub.execute_input":"2025-03-31T04:00:37.990641Z","iopub.status.idle":"2025-03-31T04:00:38.937211Z","shell.execute_reply.started":"2025-03-31T04:00:37.990613Z","shell.execute_reply":"2025-03-31T04:00:38.936311Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"('./Qwen2.5-1.5B-Instruct-Perfumassist/tokenizer_config.json',\n './Qwen2.5-1.5B-Instruct-Perfumassist/special_tokens_map.json',\n './Qwen2.5-1.5B-Instruct-Perfumassist/vocab.json',\n './Qwen2.5-1.5B-Instruct-Perfumassist/merges.txt',\n './Qwen2.5-1.5B-Instruct-Perfumassist/added_tokens.json',\n './Qwen2.5-1.5B-Instruct-Perfumassist/tokenizer.json')"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\n\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"hf_key\")\nlogin(token=hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T03:31:34.041615Z","iopub.execute_input":"2025-03-31T03:31:34.042025Z","iopub.status.idle":"2025-03-31T03:31:34.260112Z","shell.execute_reply.started":"2025-03-31T03:31:34.041996Z","shell.execute_reply":"2025-03-31T03:31:34.259365Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi()\napi.create_repo(\n    repo_id=\"phatvucoder/Qwen2.5-1.5B-Perfumassist\",\n    repo_type=\"model\",\n    private=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T03:39:25.922384Z","iopub.execute_input":"2025-03-31T03:39:25.922700Z","iopub.status.idle":"2025-03-31T03:39:26.378674Z","shell.execute_reply.started":"2025-03-31T03:39:25.922679Z","shell.execute_reply":"2025-03-31T03:39:26.377966Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"RepoUrl('https://huggingface.co/phatvucoder/Qwen2.5-1.5B-Perfumassist', endpoint='https://huggingface.co', repo_type='model', repo_id='phatvucoder/Qwen2.5-1.5B-Perfumassist')"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from huggingface_hub import upload_folder\n\nupload_folder(\n    folder_path=\"./Qwen2.5-1.5B-Instruct-Perfumassist\",\n    path_in_repo=\"\",\n    repo_id=\"phatvucoder/Qwen2.5-1.5B-Perfumassist\",\n    repo_type=\"model\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T04:01:09.646361Z","iopub.execute_input":"2025-03-31T04:01:09.646743Z","iopub.status.idle":"2025-03-31T04:01:35.620608Z","shell.execute_reply.started":"2025-03-31T04:01:09.646705Z","shell.execute_reply":"2025-03-31T04:01:35.619861Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54e130554a544ceb85a85a28ebe7996f"}},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/phatvucoder/Qwen2.5-1.5B-Perfumassist/commit/fe860fd3fc8df9d10e04bb3f8d009011e1d78cda', commit_message='Upload folder using huggingface_hub', commit_description='', oid='fe860fd3fc8df9d10e04bb3f8d009011e1d78cda', pr_url=None, repo_url=RepoUrl('https://huggingface.co/phatvucoder/Qwen2.5-1.5B-Perfumassist', endpoint='https://huggingface.co', repo_type='model', repo_id='phatvucoder/Qwen2.5-1.5B-Perfumassist'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":26}]}